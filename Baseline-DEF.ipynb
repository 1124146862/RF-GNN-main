{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T19:34:04.985791Z",
     "start_time": "2025-02-10T19:32:39.235099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Standardize the input data\n",
    "def standard_input(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    return X_scaled_df\n",
    "\n",
    "\n",
    "def load_data_DEF(random_state=42):\n",
    "    # CSV 文件路径（根据需要修改路径）\n",
    "    path = '/home/gehongfei/project/TabGNN/dataset/DEF.csv'\n",
    "    \n",
    "    # 读取 CSV 文件，CSV 文件的分隔符为逗号\n",
    "    df = pd.read_csv(path, sep=',')\n",
    "    \n",
    "    # 检查目标变量 'label' 是否存在\n",
    "    target_col = 'label'\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Error: '{target_col}' column not found in the dataset.\")\n",
    "        return None, None, None, None, None, None, None, None, None, None, None\n",
    "    \n",
    "    # 将目标变量和特征进行分离\n",
    "    y = df[target_col]\n",
    "    # 如果存在 'ID' 列，则将其和目标变量一起移除\n",
    "    if \"ID\" in df.columns:\n",
    "        X = df.drop(columns=[\"ID\", target_col])\n",
    "    else:\n",
    "        X = df.drop(columns=[target_col])\n",
    "    \n",
    "    # 划分训练集、验证集和测试集\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=random_state, stratify=y\n",
    "    )\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=2/3, random_state=random_state, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # 创建节点 mask（这里假设每一行数据对应图中的一个节点）\n",
    "    num_nodes = len(df)\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    # 根据原始数据的索引设置 mask\n",
    "    train_mask[X_train.index] = True\n",
    "    val_mask[X_valid.index] = True\n",
    "    test_mask[X_test.index] = True\n",
    "    \n",
    "    # 标准化输入（请确保 standard_input 函数已经定义）\n",
    "    X = standard_input(X)\n",
    "    X_train = standard_input(X_train)\n",
    "    X_valid = standard_input(X_valid)\n",
    "    X_test = standard_input(X_test)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_data_DEF()\n",
    "\n",
    "# Split data into train (70%), validation (10%), and test (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(max_iter=1000),  # Increase max_iter for convergence\n",
    "    \"LDA\": LinearDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "# Evaluate models on test set\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    prec = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-score': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Report summary for all models\n",
    "print(\"\\nTest Performance Summary:\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"{model}: {metrics}\")\n"
   ],
   "id": "d47e7ca4df16ddd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "\n",
      "Decision Tree Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.83      4692\n",
      "           1       0.39      0.43      0.41      1308\n",
      "\n",
      "    accuracy                           0.73      6000\n",
      "   macro avg       0.62      0.62      0.62      6000\n",
      "weighted avg       0.74      0.73      0.74      6000\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4692\n",
      "           1       0.69      0.24      0.36      1308\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.76      0.60      0.62      6000\n",
      "weighted avg       0.79      0.81      0.77      6000\n",
      "\n",
      "Training SVM...\n",
      "\n",
      "SVM Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89      4692\n",
      "           1       0.69      0.34      0.45      1308\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.76      0.65      0.67      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      4692\n",
      "           1       0.64      0.37      0.47      1308\n",
      "\n",
      "    accuracy                           0.82      6000\n",
      "   macro avg       0.74      0.66      0.68      6000\n",
      "weighted avg       0.80      0.82      0.80      6000\n",
      "\n",
      "Training Naive Bayes...\n",
      "\n",
      "Naive Bayes Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.78      4692\n",
      "           1       0.39      0.68      0.49      1308\n",
      "\n",
      "    accuracy                           0.70      6000\n",
      "   macro avg       0.64      0.69      0.64      6000\n",
      "weighted avg       0.78      0.70      0.72      6000\n",
      "\n",
      "Training MLP...\n",
      "\n",
      "MLP Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89      4692\n",
      "           1       0.62      0.38      0.47      1308\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.73      0.66      0.68      6000\n",
      "weighted avg       0.79      0.81      0.80      6000\n",
      "\n",
      "Training LDA...\n",
      "\n",
      "LDA Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89      4692\n",
      "           1       0.68      0.25      0.36      1308\n",
      "\n",
      "    accuracy                           0.81      6000\n",
      "   macro avg       0.75      0.61      0.63      6000\n",
      "weighted avg       0.79      0.81      0.77      6000\n",
      "\n",
      "\n",
      "Test Performance Summary:\n",
      "Decision Tree: {'Accuracy': 0.7316666666666667, 'Precision': 0.7411129732751655, 'Recall': 0.7316666666666667, 'F1-score': 0.736069796976699}\n",
      "Logistic Regression: {'Accuracy': 0.811, 'Precision': 0.792713241158418, 'Recall': 0.811, 'F1-score': 0.7729382457386362}\n",
      "SVM: {'Accuracy': 0.8218333333333333, 'Precision': 0.8049802414414174, 'Recall': 0.8218333333333333, 'F1-score': 0.7972583393701869}\n",
      "Random Forest: {'Accuracy': 0.8175, 'Precision': 0.7990310139419604, 'Recall': 0.8175, 'F1-score': 0.7986829656156111}\n",
      "Naive Bayes: {'Accuracy': 0.6981666666666667, 'Precision': 0.7779417086189043, 'Recall': 0.6981666666666667, 'F1-score': 0.7215153777234158}\n",
      "MLP: {'Accuracy': 0.8131666666666667, 'Precision': 0.79405029245007, 'Recall': 0.8131666666666667, 'F1-score': 0.7955897346380923}\n",
      "LDA: {'Accuracy': 0.8108333333333333, 'Precision': 0.7912759632135263, 'Recall': 0.8108333333333333, 'F1-score': 0.7746329877580671}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T18:45:18.879455Z",
     "start_time": "2025-02-10T18:45:18.872975Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "10cbbef923ec2255",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T18:45:19.112522Z",
     "start_time": "2025-02-10T18:45:19.109192Z"
    }
   },
   "cell_type": "code",
   "source": "y.shape",
   "id": "69a9da7f6871cff3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32753fddbdf32e69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
