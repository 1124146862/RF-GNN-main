{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:13:58.442118Z",
     "start_time": "2025-02-06T11:13:58.430450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standard_input(X):\n",
    "    # 标准化输入\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "def load_data_SGER1000():\n",
    "    # 读取以空格分隔的SGER CSV文件\n",
    "    path = '/home/gehongfei/project/TabGNN/dataset/SGER1000.csv'\n",
    "    df = pd.read_csv(path, sep='\\s+')\n",
    "    \n",
    "    # 确保 'kredit' 列存在\n",
    "    if 'kredit' not in df.columns:\n",
    "        print(\"Error: 'kredit' column not found.\")\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # 目标变量和特征\n",
    "    y = df['kredit']\n",
    "    X = df.drop(columns=['kredit'])\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/5, random_state=42)\n",
    "\n",
    "    # 计算节点数并创建 mask\n",
    "    num_nodes = len(df)\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    # 获取索引并设置 mask\n",
    "    train_mask[X_train.index] = True\n",
    "    test_mask[X_test.index] = True\n",
    "    \n",
    "    # 标准化输入\n",
    "    X = standard_input(X)\n",
    "    X_train = standard_input(X_train)\n",
    "    X_test = standard_input(X_test)\n",
    "    \n",
    "    return X, y, X_train, y_train, X_test, y_test, train_mask, test_mask\n",
    "\n"
   ],
   "id": "70e622b14b0f850e",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:14:04.369448Z",
     "start_time": "2025-02-06T11:14:04.355304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# 训练Random Forest并计算相似性\n",
    "# Function to compute adjacency matrix for train and test data\n",
    "def compute_adjacency_matrix(X_train, X_test, y_train, n_estimators=100, max_depth=None, threshold=0.20, random_state=42):\n",
    "    # 合并训练和测试数据\n",
    "    X_combined = pd.concat([X_train, X_test], axis=0)\n",
    "    num_samples = X_combined.shape[0]\n",
    "    \n",
    "    # 训练Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    rf.fit(X_train, y_train)  # 仅使用训练数据训练模型\n",
    "    \n",
    "    # 获取每棵树的叶子索引\n",
    "    leaf_indices = rf.apply(X_combined)\n",
    "    \n",
    "    # 计算相似性矩阵\n",
    "    adjacency_matrix = np.zeros((num_samples, num_samples))\n",
    "    for tree_idx in range(leaf_indices.shape[1]):  # 遍历每棵树\n",
    "        leaf_to_samples = {}\n",
    "        for sample_idx, leaf_id in enumerate(leaf_indices[:, tree_idx]):\n",
    "            if leaf_id not in leaf_to_samples:\n",
    "                leaf_to_samples[leaf_id] = []\n",
    "            leaf_to_samples[leaf_id].append(sample_idx)\n",
    "        \n",
    "        # 更新相似性矩阵\n",
    "        for sample_list in leaf_to_samples.values():\n",
    "            for i in sample_list:\n",
    "                for j in sample_list:\n",
    "                    if i != j:\n",
    "                        adjacency_matrix[i, j] += 1\n",
    "    \n",
    "    # 归一化相似性\n",
    "    adjacency_matrix /= adjacency_matrix.max()\n",
    "    \n",
    "    # 应用阈值，转换为二值矩阵\n",
    "    adjacency_matrix = (adjacency_matrix > threshold).astype(int)\n",
    "    \n",
    "    # 转换为稀疏矩阵\n",
    "    adjacency_matrix_sparse = csr_matrix(adjacency_matrix)\n",
    "    \n",
    "    return adjacency_matrix_sparse\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "# 从稀疏邻接矩阵提取边索引\n",
    "def adjacency_to_edge_index(adj_matrix):\n",
    "    coo_matrix = adj_matrix.tocoo()  # 转换为COO格式\n",
    "    edge_index = torch.tensor(np.vstack((coo_matrix.row, coo_matrix.col)), dtype=torch.long)\n",
    "    return edge_index\n"
   ],
   "id": "3b3d7aeb93d44e65",
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:14:06.212887Z",
     "start_time": "2025-02-06T11:14:06.199170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=1):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads)\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.dropout(x, p=0.6, training=self.training)  # 手动添加 Dropout\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)  # 在中间层也添加 Dropout\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ],
   "id": "3f9a262f549fa22b",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T12:38:48.933809Z",
     "start_time": "2025-02-06T12:38:43.818015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import numpy as np\n",
    "\n",
    "# 载入数据\n",
    "X, y, X_train,y_train, X_test,y_test, train_mask, test_mask = load_data_SGER1000()\n",
    "adj_matrix = compute_adjacency_matrix(X_train, X_test, y_train)\n",
    "edge_index = adjacency_to_edge_index(adj_matrix)\n",
    "\n",
    "num_features = X.shape[1]\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "edge_index = adjacency_to_edge_index(adj_matrix)\n",
    "\n",
    "# 转换数据格式\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "\n",
    "# 创建 PyG Data 对象\n",
    "data = Data(x=X_tensor, y=y_tensor, edge_index=edge_index, train_mask=train_mask, test_mask=test_mask)\n",
    "\n",
    "# 计算类别权重（解决类别不平衡）\n",
    "class_counts = np.bincount(y_tensor.numpy())\n",
    "print(class_counts)\n",
    "weights = torch.tensor(1.0 / class_counts, dtype=torch.float)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "# 定义 GNN 模型\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GraphSAGE(in_channels=num_features, hidden_channels=128, out_channels=num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# 训练和测试代码\n",
    "\n",
    "def train(model, data, optimizer, criterion, epochs=200):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        test_preds = preds[data.test_mask]\n",
    "        test_labels = data.y[data.test_mask]\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(test_labels.cpu(), test_preds.cpu()))\n",
    "\n",
    "# 训练模型\n",
    "train(model, data, optimizer, criterion, epochs=80)\n",
    "\n",
    "# 在测试集上进行评估\n",
    "test(model, data)\n",
    "\n"
   ],
   "id": "7841726c18c8272a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Training Logistic Regression...\n",
      "Training SVM...\n",
      "Training Random Forest...\n",
      "Training Naive Bayes...\n",
      "Training MLP...\n",
      "Training LDA...\n",
      "\n",
      "Test Performance:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       143\n",
      "           1       0.54      0.44      0.49        57\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.67      0.65      0.65       200\n",
      "weighted avg       0.72      0.73      0.73       200\n",
      "\n",
      "\n",
      "Best Model: MLP based on F1-score\n"
     ]
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T11:38:27.061487Z",
     "start_time": "2025-02-06T11:38:06.976745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def train_and_evaluate(model, data, optimizer, criterion, epochs=200):\n",
    "    \"\"\" 训练并评估模型 \"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        test_preds = preds[data.test_mask]\n",
    "        test_labels = data.y[data.test_mask]\n",
    "        # 在测试集上进行评估\n",
    "        test(model, data)\n",
    "        return f1_score(test_labels.cpu(), test_preds.cpu(), average='macro')\n",
    "\n",
    "class GraphSAGEImproved(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout):\n",
    "        super(GraphSAGEImproved, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.dropout = dropout\n",
    "        # 第一层\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        # 额外隐藏层\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "\n",
    "        # 输出层\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for i in range(len(self.convs) - 1):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 随机搜索超参数优化\n",
    "def random_search(data, num_trials=10):\n",
    "    param_grid = {\n",
    "        'hidden_channels': [20, 40, 60, 80, 100, 120, 140, 160, 180, 200],\n",
    "        'num_layers': [1, 2, 3, 4],\n",
    "        'learning_rate': [0.01, 0.005, 0.001],\n",
    "        'epochs': [30, 50, 100, 150],\n",
    "        'dropout': [0.3, 0.4, 0.5, 0.6]\n",
    "    }\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_params = None\n",
    "    \n",
    "    for _ in range(num_trials):\n",
    "        hidden_channels = random.choice(param_grid['hidden_channels'])\n",
    "        num_layers = random.choice(param_grid['num_layers'])\n",
    "        lr = random.choice(param_grid['learning_rate'])\n",
    "        epochs = random.choice(param_grid['epochs'])\n",
    "        dropout = random.choice(param_grid['dropout'])\n",
    "        \n",
    "        model = GraphSAGEImproved(num_features, hidden_channels, num_classes, num_layers, dropout)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "        \n",
    "        f1 = train_and_evaluate(model, data, optimizer, criterion, epochs)\n",
    "        print(f\"Params: {(hidden_channels, num_layers, lr, epochs, dropout)}, F1 Score: {f1:.4f}\")\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = (hidden_channels, num_layers, lr, epochs, dropout)\n",
    "    \n",
    "    print(f\"Best Params: {best_params}, Best F1 Score: {best_f1:.4f}\")\n",
    "    return best_params\n",
    "\n",
    "# 运行随机搜索\n",
    "best_hyperparams = random_search(data)\n"
   ],
   "id": "ba2bae4562c3e108",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80       138\n",
      "           1       0.55      0.52      0.53        62\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.67      0.66      0.67       200\n",
      "weighted avg       0.72      0.72      0.72       200\n",
      "\n",
      "Params: (128, 3, 0.01, 100, 0.3), F1 Score: 0.6667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       138\n",
      "           1       0.54      0.63      0.58        62\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.68      0.69      0.69       200\n",
      "weighted avg       0.73      0.72      0.73       200\n",
      "\n",
      "Params: (64, 3, 0.005, 100, 0.5), F1 Score: 0.6858\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.76      0.77       138\n",
      "           1       0.51      0.55      0.53        62\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.70      0.69      0.70       200\n",
      "\n",
      "Params: (64, 3, 0.005, 50, 0.3), F1 Score: 0.6510\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.77      0.78       138\n",
      "           1       0.52      0.55      0.53        62\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.65      0.66      0.66       200\n",
      "weighted avg       0.71      0.70      0.70       200\n",
      "\n",
      "Params: (64, 2, 0.01, 100, 0.5), F1 Score: 0.6553\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79       138\n",
      "           1       0.52      0.48      0.50        62\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.65      0.64      0.64       200\n",
      "weighted avg       0.69      0.70      0.70       200\n",
      "\n",
      "Params: (128, 2, 0.005, 100, 0.3), F1 Score: 0.6429\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       138\n",
      "           1       0.53      0.58      0.55        62\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.72      0.71      0.71       200\n",
      "\n",
      "Params: (64, 2, 0.01, 100, 0.3), F1 Score: 0.6695\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79       138\n",
      "           1       0.54      0.60      0.57        62\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.68      0.69      0.68       200\n",
      "weighted avg       0.73      0.72      0.72       200\n",
      "\n",
      "Params: (128, 2, 0.01, 50, 0.5), F1 Score: 0.6809\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78       138\n",
      "           1       0.51      0.50      0.50        62\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.64      0.64      0.64       200\n",
      "weighted avg       0.69      0.69      0.69       200\n",
      "\n",
      "Params: (64, 3, 0.005, 100, 0.3), F1 Score: 0.6419\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76       138\n",
      "           1       0.48      0.52      0.50        62\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.63      0.63      0.63       200\n",
      "weighted avg       0.69      0.68      0.68       200\n",
      "\n",
      "Params: (64, 3, 0.01, 50, 0.3), F1 Score: 0.6324\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79       138\n",
      "           1       0.54      0.53      0.54        62\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.67      0.66      0.67       200\n",
      "weighted avg       0.71      0.71      0.71       200\n",
      "\n",
      "Params: (128, 2, 0.01, 50, 0.3), F1 Score: 0.6654\n",
      "Best Params: (64, 3, 0.005, 100, 0.5), Best F1 Score: 0.6858\n"
     ]
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T16:15:51.611884Z",
     "start_time": "2025-02-05T16:15:51.606733Z"
    }
   },
   "cell_type": "code",
   "source": "type(X)",
   "id": "95634a5f4440be3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af942583584a4a21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
