{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839f95dd4785f5af",
   "metadata": {},
   "source": [
    "### util function"
   ]
  },
  {
   "cell_type": "code",
   "id": "2569111fcf584f28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:25:43.281876Z",
     "start_time": "2025-02-10T23:22:26.614002Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def standard_input(X):\n",
    "    \"\"\"\n",
    "    标准化输入，这里直接返回原数据；如有需要，可在此处添加标准化处理\n",
    "    \"\"\"\n",
    "    return X\n",
    "\n",
    "def load_data_DEF(random_state=42):\n",
    "    \"\"\"\n",
    "    从 CSV 文件中加载数据，并划分训练、验证、测试集，同时构造节点 mask\n",
    "    \"\"\"\n",
    "    # CSV 文件路径（根据实际情况修改）\n",
    "    path = '/home/gehongfei/project/TabGNN/dataset/DEF.csv'\n",
    "    \n",
    "    df = pd.read_csv(path, sep=',')\n",
    "    \n",
    "    target_col = 'label'\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Error: '{target_col}' column not found in the dataset.\")\n",
    "        return None, None, None, None, None, None, None, None, None, None, None\n",
    "    \n",
    "    y = df[target_col]\n",
    "    if \"ID\" in df.columns:\n",
    "        X = df.drop(columns=[\"ID\", target_col])\n",
    "    else:\n",
    "        X = df.drop(columns=[target_col])\n",
    "    \n",
    "    # 划分训练、验证和测试集\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=random_state, stratify=y\n",
    "    )\n",
    "    X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=2/3, random_state=random_state, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    # 创建节点 mask（假设每一行数据代表图中的一个节点）\n",
    "    num_nodes = len(df)\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    val_mask   = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask  = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    train_mask[X_train.index] = True\n",
    "    val_mask[X_valid.index]   = True\n",
    "    test_mask[X_test.index]   = True\n",
    "    \n",
    "    # 如果需要标准化，可在此处实现\n",
    "    X = standard_input(X)\n",
    "    X_train = standard_input(X_train)\n",
    "    X_valid = standard_input(X_valid)\n",
    "    X_test  = standard_input(X_test)\n",
    "    \n",
    "    return X, y, X_train, X_valid, X_test, y_train, y_valid, y_test, train_mask, val_mask, test_mask\n",
    "\n",
    "def compute_adjacency_matrix_by_prototypes(X_train, X_valid, X_test, y_train, y_valid,\n",
    "                                             n_clusters=1000, n_estimators=50, max_depth=None,\n",
    "                                             random_state=42):\n",
    "    \"\"\"\n",
    "    利用原型构造邻接矩阵的两步方法：\n",
    "      ① 对所有样本聚类（KMeans），得到 n_clusters 个原型中心；\n",
    "      ② 步骤一：利用训练+验证数据训练的随机森林，对原型集合构造边，得到原型相似性矩阵 A_proto（尺寸 n_clusters×n_clusters）；  \n",
    "          步骤二：对于每个原型对应的簇，利用该原型和其簇内样本构造局部数据集，利用随机森林构造局部边（仅计算簇内样本间的相似性）；  \n",
    "          将两部分边合并，得到全局邻接矩阵。\n",
    "    返回:\n",
    "      - 全局邻接矩阵（csr_matrix 格式）\n",
    "      - 每个样本的聚类标签（长度为样本数的数组）\n",
    "    \"\"\"\n",
    "    # ① 合并所有样本，便于后续操作\n",
    "    X_all = pd.concat([X_train, X_valid, X_test], axis=0)\n",
    "    num_samples = X_all.shape[0]\n",
    "    \n",
    "    # 聚类：显式设置 n_init 以避免 FutureWarning\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_all)\n",
    "    prototypes = kmeans.cluster_centers_  # shape: (n_clusters, num_features)\n",
    "    \n",
    "    # ② 步骤一：利用训练+验证数据构造原型之间的边\n",
    "    X_train_valid = pd.concat([X_train, X_valid], axis=0)\n",
    "    y_train_valid = pd.concat([y_train, y_valid], axis=0)\n",
    "    \n",
    "    rf_proto = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                      random_state=random_state)\n",
    "    rf_proto.fit(X_train_valid, y_train_valid)\n",
    "    \n",
    "    # 将原型转换为 DataFrame，确保列名与 X_all 一致\n",
    "    df_prototypes = pd.DataFrame(prototypes, columns=X_all.columns)\n",
    "    leaf_indices_proto = rf_proto.apply(df_prototypes)  # shape: (n_clusters, n_trees)\n",
    "    \n",
    "    A_proto = np.zeros((n_clusters, n_clusters))\n",
    "    num_trees = leaf_indices_proto.shape[1]\n",
    "    for tree_idx in tqdm(range(num_trees), desc=\"计算原型相似性\"):\n",
    "        leaf_to_protos = {}\n",
    "        for proto_idx, leaf_id in enumerate(leaf_indices_proto[:, tree_idx]):\n",
    "            leaf_to_protos.setdefault(leaf_id, []).append(proto_idx)\n",
    "        for proto_list in leaf_to_protos.values():\n",
    "            # 两两累加得分\n",
    "            for i in proto_list:\n",
    "                for j in proto_list:\n",
    "                    if i != j:\n",
    "                        A_proto[i, j] += 1\n",
    "    if A_proto.max() > 0:\n",
    "        A_proto = A_proto / A_proto.max()  # 归一化至 [0,1]\n",
    "    \n",
    "    # ③ 构造全局邻接矩阵，初始化为零矩阵\n",
    "    global_adj = np.zeros((num_samples, num_samples))\n",
    "    \n",
    "    # 对于不同簇的样本，直接赋值原型相似性（步骤一的边）\n",
    "    # 即：对于任意两个样本 i, j（所属簇分别为 a 和 b，且 a != b），\n",
    "    # global_adj[i, j] = A_proto[a, b]\n",
    "    for cluster_a in tqdm(range(n_clusters), desc=\"赋值不同簇之间的边\"):\n",
    "        idx_a = np.where(cluster_labels == cluster_a)[0]\n",
    "        for cluster_b in range(cluster_a + 1, n_clusters):\n",
    "            idx_b = np.where(cluster_labels == cluster_b)[0]\n",
    "            weight = A_proto[cluster_a, cluster_b]\n",
    "            if weight > 0:\n",
    "                global_adj[np.ix_(idx_a, idx_b)] = weight\n",
    "                global_adj[np.ix_(idx_b, idx_a)] = weight\n",
    "\n",
    "    # ④ 步骤二：对于每个簇，计算局部相似性边（仅针对同一簇内的样本）\n",
    "    for cluster in tqdm(range(n_clusters), desc=\"计算同簇局部边\"):\n",
    "        indices = np.where(cluster_labels == cluster)[0]\n",
    "        if len(indices) < 2:\n",
    "            continue  # 如果簇内样本不足2个，则跳过\n",
    "        \n",
    "        # 构造局部数据集：第一行为该簇的原型，其余为该簇内样本\n",
    "        df_proto = pd.DataFrame([prototypes[cluster]], columns=X_all.columns)\n",
    "        df_samples = X_all.iloc[indices].reset_index(drop=True)\n",
    "        local_data = pd.concat([df_proto, df_samples], ignore_index=True)\n",
    "        # 构造标签：原型设为 0，簇内样本设为 1\n",
    "        local_labels = [0] + [1] * len(indices)\n",
    "        \n",
    "        try:\n",
    "            rf_local = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                              random_state=random_state)\n",
    "            rf_local.fit(local_data, local_labels)\n",
    "        except Exception as e:\n",
    "            print(f\"局部随机森林训练失败（簇 {cluster}）：{e}\")\n",
    "            continue\n",
    "        \n",
    "        leaf_indices_local = rf_local.apply(local_data)  # shape: (num_points, n_trees_local)\n",
    "        A_local = np.zeros((len(indices) + 1, len(indices) + 1))\n",
    "        num_trees_local = leaf_indices_local.shape[1]\n",
    "        for tree_idx in range(num_trees_local):\n",
    "            leaf_to_nodes = {}\n",
    "            for node_idx, leaf_id in enumerate(leaf_indices_local[:, tree_idx]):\n",
    "                leaf_to_nodes.setdefault(leaf_id, []).append(node_idx)\n",
    "            for node_list in leaf_to_nodes.values():\n",
    "                for i_local in node_list:\n",
    "                    for j_local in node_list:\n",
    "                        if i_local != j_local:\n",
    "                            A_local[i_local, j_local] += 1\n",
    "        if A_local.max() > 0:\n",
    "            A_local = A_local / A_local.max()\n",
    "        # 只保留样本之间的相似性（去除原型对应的行和列，即索引 1:）\n",
    "        A_local_samples = A_local[1:, 1:]\n",
    "        # 将局部相似性累加到全局邻接矩阵的相应位置（仅针对同一簇内的样本）\n",
    "        for i, global_i in enumerate(indices):\n",
    "            for j, global_j in enumerate(indices):\n",
    "                if global_i != global_j:\n",
    "                    global_adj[global_i, global_j] += A_local_samples[i, j]\n",
    "    \n",
    "    # ⑤ 对全局邻接矩阵归一化（如果最大值大于0）\n",
    "    if global_adj.max() > 0:\n",
    "        global_adj = global_adj / global_adj.max()\n",
    "    \n",
    "    return csr_matrix(global_adj), cluster_labels\n",
    "\n",
    "def adjacency_to_edge_index(adj_matrix, cluster_labels, proto_threshold=0.05, local_threshold=0.05):\n",
    "    \"\"\"\n",
    "    将稀疏邻接矩阵转换为边索引，并根据两种不同的阈值进行二值化：\n",
    "      - 跨簇（原型）边：仅保留边权大于 proto_threshold 的边；\n",
    "      - 同簇内（局部）边：仅保留边权大于 local_threshold 的边。\n",
    "    \n",
    "    参数:\n",
    "      adj_matrix: scipy.sparse 格式的邻接矩阵\n",
    "      cluster_labels: 长度为节点数的数组，记录每个节点所属的聚类标签\n",
    "      proto_threshold: 用于过滤跨簇边（原型边）的阈值\n",
    "      local_threshold: 用于过滤同簇内边（局部边）的阈值\n",
    "    \n",
    "    返回:\n",
    "      edge_index: torch.tensor 格式的边索引，形状为 [2, num_edges]\n",
    "    \"\"\"\n",
    "    if not isinstance(cluster_labels, np.ndarray):\n",
    "        cluster_labels = np.array(cluster_labels)\n",
    "    \n",
    "    # 将稀疏矩阵转换为 NumPy 数组\n",
    "    adj_array = adj_matrix.toarray()\n",
    "    \n",
    "    # 构造同簇与跨簇的掩码\n",
    "    same_mask = (cluster_labels[:, None] == cluster_labels[None, :])\n",
    "    cross_mask = ~same_mask\n",
    "    \n",
    "    # 分别对同簇和跨簇位置应用不同的阈值\n",
    "    binary_adj = np.zeros_like(adj_array, dtype=int)\n",
    "    binary_adj[same_mask] = (adj_array[same_mask] > local_threshold).astype(int)\n",
    "    binary_adj[cross_mask] = (adj_array[cross_mask] > proto_threshold).astype(int)\n",
    "    \n",
    "    # 转换为 COO 格式后构造 edge_index\n",
    "    coo = csr_matrix(binary_adj).tocoo()\n",
    "    edge_index = torch.tensor(np.vstack((coo.row, coo.col)), dtype=torch.long)\n",
    "    \n",
    "    print(\"邻接矩阵转换完成！Edge index 维度:\", edge_index.shape)\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "X, y, X_train, X_valid, X_test, y_train, y_valid, y_test, train_mask, val_mask, test_mask = load_data_DEF()\n",
    "print(\"数据加载完成！\")\n",
    "\n",
    "# 计算基于原型构造的全局邻接矩阵，并获得每个节点的聚类标签\n",
    "print(\"开始计算基于原型中心的邻接矩阵...\")\n",
    "adj_matrix, cluster_labels = compute_adjacency_matrix_by_prototypes(\n",
    "    X_train, X_valid, X_test, y_train, y_valid,\n",
    "    n_clusters=1000, n_estimators=50, max_depth=None, random_state=42\n",
    ")\n",
    "print(\"邻接矩阵计算完成，形状为：\", adj_matrix.shape)\n",
    "\n",
    "# 将邻接矩阵转换为 edge_index 格式，并分别设置跨簇和同簇边的阈值\n",
    "edge_index = adjacency_to_edge_index(adj_matrix, cluster_labels, proto_threshold=0.05, local_threshold=0.15)\n",
    "print(\"邻接矩阵转换完成！\")\n",
    "print(\"Edge index 维度:\", edge_index.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据加载完成！\n",
      "开始计算基于原型中心的邻接矩阵...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "计算原型相似性: 100%|██████████████████████████| 50/50 [00:00<00:00, 263.53it/s]\n",
      "赋值不同簇之间的边: 100%|███████████████████| 1000/1000 [00:14<00:00, 70.27it/s]\n",
      "计算同簇局部边: 100%|███████████████████████| 1000/1000 [01:47<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "邻接矩阵计算完成，形状为： (30000, 30000)\n",
      "邻接矩阵转换完成！Edge index 维度: torch.Size([2, 102846068])\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 102846068])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:27:38.129234Z",
     "start_time": "2025-02-10T23:27:16.429517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将邻接矩阵转换为 edge_index 格式，并分别设置跨簇和同簇边的阈值\n",
    "edge_index = adjacency_to_edge_index(adj_matrix, cluster_labels, proto_threshold=0.15, local_threshold=0.35)\n",
    "print(\"邻接矩阵转换完成！\")\n",
    "print(\"Edge index 维度:\", edge_index.shape)"
   ],
   "id": "a5997f89b9919e74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "邻接矩阵转换完成！Edge index 维度: torch.Size([2, 51051092])\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 51051092])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T23:16:24.387060Z",
     "start_time": "2025-02-10T23:16:11.697324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# 随机选择 5 个非零值进行打印\n",
    "sampled_values = np.random.choice(adj_matrix.data, size=min(5, len(adj_matrix.data)), replace=False)\n",
    "print(\"随机抽取的5个非零邻接矩阵值：\", sampled_values)\n"
   ],
   "id": "48828ee99c5c3bad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机抽取的5个非零邻接矩阵值： [0.075 0.075 0.025 0.025 0.025]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Batch-Based Optimization",
   "id": "7bd858fd7f633aac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T22:50:08.390404Z",
     "start_time": "2025-02-10T22:49:50.861827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from tqdm import tqdm  # 用于显示训练进度\n",
    "\n",
    "# 假设设备定义如下\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#########################################\n",
    "# 1. 定义模型\n",
    "#########################################\n",
    "# GraphSAGE 模型（包含残差结构和 dropout，每层隐藏单元数递减至上一层的3/4）\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        参数说明：\n",
    "          in_channels: 输入特征维度\n",
    "          hidden_channels: 第一层的隐藏单元数\n",
    "          out_channels: 输出类别数\n",
    "          num_layers: 图卷积层的总层数（至少为 1）\n",
    "          dropout_rate: dropout 概率\n",
    "        \"\"\"\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.residuals = torch.nn.ModuleList()\n",
    "        # 第一层：从 in_channels 到 hidden_channels\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        if in_channels != hidden_channels:\n",
    "            self.residuals.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        else:\n",
    "            self.residuals.append(torch.nn.Identity())\n",
    "        current_hidden = hidden_channels\n",
    "        # 后续每一层的隐藏单元数为上一层的 3/4（向下取整，最小为 1）\n",
    "        for _ in range(num_layers - 1):\n",
    "            next_hidden = max(1, int(current_hidden * 3 / 4))\n",
    "            self.convs.append(SAGEConv(current_hidden, next_hidden))\n",
    "            if current_hidden != next_hidden:\n",
    "                self.residuals.append(torch.nn.Linear(current_hidden, next_hidden))\n",
    "            else:\n",
    "                self.residuals.append(torch.nn.Identity())\n",
    "            current_hidden = next_hidden\n",
    "        # 全连接层：将最后一层的隐藏向量映射到输出类别\n",
    "        self.fc = torch.nn.Linear(current_hidden, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        \"\"\"提取节点表示：依次通过图卷积层、残差连接、ReLU 和 dropout（适用于全图或子图）\"\"\"\n",
    "        for conv, res in zip(self.convs, self.residuals):\n",
    "            out = conv(x, edge_index)\n",
    "            res_x = res(x)\n",
    "            x = self.dropout(torch.relu(out + res_x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.encode(data.x, data.edge_index)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# GAT 模型（包含残差结构和 dropout，每层隐藏单元数递减至上一层的3/4）\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout_rate=0.5, heads=1, concat=True):\n",
    "        \"\"\"\n",
    "        参数说明：\n",
    "          in_channels: 输入特征维度\n",
    "          hidden_channels: 第一层的隐藏单元数\n",
    "          out_channels: 输出类别数\n",
    "          num_layers: 图卷积层的总层数（至少为 1）\n",
    "          dropout_rate: dropout 概率（同时用于 GATConv 内部 dropout）\n",
    "          heads: 注意力头的数量\n",
    "          concat: 是否拼接多头输出（True）或取平均（False）\n",
    "        \"\"\"\n",
    "        super(GAT, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.residuals = torch.nn.ModuleList()\n",
    "        # 第一层\n",
    "        self.convs.append(GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout_rate, concat=concat))\n",
    "        out_dim = hidden_channels * heads if concat else hidden_channels\n",
    "        if in_channels != out_dim:\n",
    "            self.residuals.append(torch.nn.Linear(in_channels, out_dim))\n",
    "        else:\n",
    "            self.residuals.append(torch.nn.Identity())\n",
    "        current_dim = out_dim\n",
    "        # 后续层\n",
    "        for _ in range(num_layers - 1):\n",
    "            next_hidden = max(1, int(current_dim * 3 / 4))\n",
    "            self.convs.append(GATConv(current_dim, next_hidden, heads=heads, dropout=dropout_rate, concat=concat))\n",
    "            new_out_dim = next_hidden * heads if concat else next_hidden\n",
    "            if current_dim != new_out_dim:\n",
    "                self.residuals.append(torch.nn.Linear(current_dim, new_out_dim))\n",
    "            else:\n",
    "                self.residuals.append(torch.nn.Identity())\n",
    "            current_dim = new_out_dim\n",
    "        self.fc = torch.nn.Linear(current_dim, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        \"\"\"提取节点表示：依次通过 GAT 层、残差连接、ReLU 和 dropout\"\"\"\n",
    "        for conv, res in zip(self.convs, self.residuals):\n",
    "            out = conv(x, edge_index)\n",
    "            res_x = res(x)\n",
    "            x = self.dropout(torch.relu(out + res_x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.encode(data.x, data.edge_index)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "#########################################\n",
    "# 2. 定义损失函数\n",
    "#########################################\n",
    "# Focal Loss（用于处理类别不平衡）\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  \n",
    "        self.reduction = reduction\n",
    "        self.ce = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (list, np.ndarray)):\n",
    "                alpha = inputs.new_tensor(self.alpha)\n",
    "            else:\n",
    "                alpha = self.alpha\n",
    "            at = alpha.gather(0, targets.data)\n",
    "            ce_loss = at * ce_loss\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        return focal_loss.mean() if self.reduction == \"mean\" else focal_loss.sum()\n",
    "\n",
    "# 修改后的普通对比学习损失（不使用 mask）\n",
    "class SupConLoss(torch.nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            temperature: 温度参数\n",
    "        \"\"\"\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: [batch_size, n_views, feature_dim]\n",
    "                      要求每个样本至少有两个视图，视图之间互为正样本，其余样本均为负样本。\n",
    "        Returns:\n",
    "            对比损失（InfoNCE Loss）\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` 需要形状为 [batch_size, n_views, feature_dim]')\n",
    "        batch_size, n_views, feature_dim = features.shape\n",
    "\n",
    "        # 将多个视图拼接为 [batch_size*n_views, feature_dim]\n",
    "        features = features.view(batch_size * n_views, feature_dim)\n",
    "        # 对每个特征进行 L2 归一化\n",
    "        features = torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "\n",
    "        # 计算相似度矩阵，形状 [batch_size*n_views, batch_size*n_views]\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        # 构造正样本掩码：同一原始样本（即同一 batch 中的不同视图）的两两之间为正样本\n",
    "        labels = torch.arange(batch_size, device=device).repeat_interleave(n_views)\n",
    "        mask = torch.eq(labels.unsqueeze(1), labels.unsqueeze(0)).float()\n",
    "        # 去除自身对比（对角线置 0）\n",
    "        self_mask = torch.eye(mask.shape[0], device=device)\n",
    "        mask = mask - self_mask\n",
    "\n",
    "        # 计算 exp(similarity)\n",
    "        exp_sim = torch.exp(similarity_matrix) * (1 - self_mask)\n",
    "        # 对每个 anchor，分母为除自身外所有样本的 exp(sim)\n",
    "        denom = exp_sim.sum(dim=1, keepdim=True) + 1e-8\n",
    "\n",
    "        # 计算仅正样本对的对数概率\n",
    "        log_prob = similarity_matrix - torch.log(denom)\n",
    "        numerator = (mask * log_prob).sum(dim=1)\n",
    "        # 正样本个数（防止除 0）\n",
    "        pos_count = mask.sum(dim=1) + 1e-8\n",
    "        loss = - (numerator / pos_count)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "#########################################\n",
    "# 3. 数据增强方法\n",
    "#########################################\n",
    "# 原始的特征扰动（用于 \"feature\" 增强方式）\n",
    "def perturb_features(features, noise_level=0.1):\n",
    "    \"\"\"对特征进行扰动，生成增强视图\"\"\"\n",
    "    noise = torch.randn_like(features) * noise_level\n",
    "    return features + noise\n",
    "\n",
    "# 节点丢弃\n",
    "def augment_node_drop(features, edge_index, drop_prob=0.1):\n",
    "    \"\"\"\n",
    "    节点丢弃：以一定概率丢弃节点（将被丢弃节点的特征置零，\n",
    "    同时删除其相关边，但保持节点的序号不变）。\n",
    "    \"\"\"\n",
    "    if isinstance(drop_prob, (list, tuple)):\n",
    "        drop_prob = float(drop_prob[0])\n",
    "    num_nodes = features.shape[0]\n",
    "    keep_mask = (torch.rand(num_nodes, device=features.device) > drop_prob)\n",
    "    features_aug = features * keep_mask.unsqueeze(1).float()\n",
    "    src, dst = edge_index\n",
    "    valid_edge_mask = keep_mask[src] & keep_mask[dst]\n",
    "    edge_index_aug = edge_index[:, valid_edge_mask]\n",
    "    return features_aug, edge_index_aug\n",
    "\n",
    "# 边丢弃\n",
    "def augment_edge_drop(features, edge_index, drop_prob=0.1):\n",
    "    \"\"\"\n",
    "    边丢弃：以一定概率删除边，但保留所有节点和原始特征。\n",
    "    \"\"\"\n",
    "    if isinstance(drop_prob, (list, tuple)):\n",
    "        drop_prob = float(drop_prob[0])\n",
    "    num_edges = edge_index.shape[1]\n",
    "    mask = (torch.rand(num_edges, device=edge_index.device) > drop_prob)\n",
    "    edge_index_aug = edge_index[:, mask]\n",
    "    return features, edge_index_aug\n",
    "\n",
    "# 边扰动\n",
    "def augment_edge_perturb(features, edge_index, drop_prob=0.1):\n",
    "    \"\"\"\n",
    "    边扰动：先以一定概率删除部分边，再随机添加一些新的边，\n",
    "    添加的新边数量与被删除边的数量相当。\n",
    "    \"\"\"\n",
    "    if isinstance(drop_prob, (list, tuple)):\n",
    "        drop_prob = float(drop_prob[0])\n",
    "    num_edges = edge_index.shape[1]\n",
    "    num_nodes = features.shape[0]\n",
    "    mask = (torch.rand(num_edges, device=edge_index.device) > drop_prob)\n",
    "    edge_index_dropped = edge_index[:, mask]\n",
    "    num_dropped = num_edges - mask.sum().item()\n",
    "    if num_dropped > 0:\n",
    "        new_edges = torch.randint(0, num_nodes, (2, num_dropped), device=features.device)\n",
    "        edge_index_aug = torch.cat([edge_index_dropped, new_edges], dim=1)\n",
    "    else:\n",
    "        edge_index_aug = edge_index_dropped\n",
    "    return features, edge_index_aug\n",
    "\n",
    "def augment_data(data, aug_method=\"feature\", aug_ratio=0.1):\n",
    "    \"\"\"\n",
    "    根据指定的增强方式对图数据进行增强，返回增强后的节点特征和 edge_index。\n",
    "    参数:\n",
    "      aug_method: \"feature\"（特征扰动）, \"node_drop\", \"edge_drop\", \"edge_perturb\"\n",
    "      aug_ratio: 控制增强强度（例如噪声水平或丢弃比例）\n",
    "    \"\"\"\n",
    "    if aug_method == \"feature\":\n",
    "        x_aug = perturb_features(data.x, noise_level=aug_ratio)\n",
    "        edge_index_aug = data.edge_index  # 图结构不变\n",
    "        return x_aug, edge_index_aug\n",
    "    elif aug_method == \"node_drop\":\n",
    "        return augment_node_drop(data.x, data.edge_index, drop_prob=aug_ratio)\n",
    "    elif aug_method == \"edge_drop\":\n",
    "        return augment_edge_drop(data.x, data.edge_index, drop_prob=aug_ratio)\n",
    "    elif aug_method == \"edge_perturb\":\n",
    "        return augment_edge_perturb(data.x, data.edge_index, drop_prob=aug_ratio)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown augmentation method: {aug_method}\")\n",
    "\n",
    "#########################################\n",
    "# 3.1 辅助函数：提取 mini-batch 子图\n",
    "#########################################\n",
    "def get_mini_batch_data(data, batch_node_idx, num_hops):\n",
    "    \"\"\"\n",
    "    对单图中一小批节点（batch_node_idx）提取 k-hop 子图。\n",
    "    使用 torch_geometric.utils.k_hop_subgraph 进行子图提取，并 relabel 节点。\n",
    "    返回：\n",
    "      sub_data: 包含子图的 Data 对象（x, edge_index, y 以及 mask 可选）\n",
    "      mapping: 一个长整型张量，指示子图中哪一部分对应原始 batch_node_idx（目标节点在子图中的索引）\n",
    "    \"\"\"\n",
    "    # k_hop_subgraph 返回：(subset, sub_edge_index, mapping, edge_mask)\n",
    "    subset, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "        node_idx=batch_node_idx, num_hops=num_hops, edge_index=data.edge_index, relabel_nodes=True)\n",
    "    sub_data = Data(x=data.x[subset], edge_index=sub_edge_index, y=data.y[subset])\n",
    "    # 如果原始 data 定义了 train/val/test mask，则在子图中也保留（注意：mask 按 subset 索引提取）\n",
    "    if hasattr(data, 'train_mask'):\n",
    "        sub_data.train_mask = data.train_mask[subset]\n",
    "    if hasattr(data, 'val_mask'):\n",
    "        sub_data.val_mask = data.val_mask[subset]\n",
    "    if hasattr(data, 'test_mask'):\n",
    "        sub_data.test_mask = data.test_mask[subset]\n",
    "    return sub_data, mapping\n",
    "\n",
    "#########################################\n",
    "# 4. 训练函数（预训练 + 微调）——mini-batch 版（基于 k_hop_subgraph）\n",
    "#########################################\n",
    "def pretrain_model(data, model, optimizer, criterion_contrast, num_epochs=200, aug_method=\"feature\", aug_ratio=0.1, batch_size=64):\n",
    "    \"\"\"\n",
    "    预训练阶段：仅使用对比损失训练模型（不计算 Focal Loss）。\n",
    "    采用 mini-batch 方式，先对训练集中的一批目标节点提取 k-hop 子图，\n",
    "    再对该子图进行数据增强生成两视图，最后计算对比损失（仅对 batch 中的目标节点计算）。\n",
    "    使用 tqdm 显示每个 epoch 以及 batch 的进度和损失。\n",
    "    \"\"\"\n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1).tolist()\n",
    "    num_hops = len(model.convs)  # 以模型层数作为子图的 hop 数\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "        loader = DataLoader(train_idx, batch_size=batch_size, shuffle=True)\n",
    "        # 使用 tqdm 包裹 batch 迭代\n",
    "        pbar = tqdm(loader, desc=f\"Pretrain Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for batch in pbar:\n",
    "            batch = batch.clone().detach().to(device)\n",
    "            sub_data, mapping = get_mini_batch_data(data, batch, num_hops)\n",
    "            sub_data = sub_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_aug1, edge_index1 = augment_data(sub_data, aug_method, aug_ratio)\n",
    "            x_aug2, edge_index2 = augment_data(sub_data, aug_method, aug_ratio)\n",
    "            embedding_aug1 = model.encode(x_aug1, edge_index1)\n",
    "            embedding_aug2 = model.encode(x_aug2, edge_index2)\n",
    "            target_emb1 = embedding_aug1[mapping]\n",
    "            target_emb2 = embedding_aug2[mapping]\n",
    "            features_aug = torch.stack([target_emb1, target_emb2], dim=1)\n",
    "            loss = criterion_contrast(features_aug)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * len(batch)\n",
    "            count += len(batch)\n",
    "            avg_loss = total_loss / count\n",
    "            pbar.set_postfix(batch_loss=f\"{loss.item():.4f}\", avg_loss=f\"{avg_loss:.4f}\")\n",
    "        print(f\"Pretrain Epoch {epoch+1}/{num_epochs}, Contrast Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            preds = out[data.val_mask].argmax(dim=1)\n",
    "            true = data.y[data.val_mask]\n",
    "            val_f1 = f1_score(true.cpu(), preds.cpu(), average=\"macro\")\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    return best_model_state\n",
    "\n",
    "def fine_tune_model(data, model, optimizer, criterion_focal, num_epochs=50, batch_size=64):\n",
    "    \"\"\"\n",
    "    微调阶段：仅使用 Focal Loss 进行训练（不计算对比损失）。\n",
    "    同样采用 mini-batch（基于 k_hop 子图）方式训练，损失仅在目标节点上计算。\n",
    "    使用 tqdm 实时显示每个 epoch 与 batch 的训练进度和损失信息。\n",
    "    \"\"\"\n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1).tolist()\n",
    "    num_hops = len(model.convs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "        loader = DataLoader(train_idx, batch_size=batch_size, shuffle=True)\n",
    "        pbar = tqdm(loader, desc=f\"Fine-tune Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for batch in pbar:\n",
    "            batch = batch.clone().detach().to(device)\n",
    "            sub_data, mapping = get_mini_batch_data(data, batch, num_hops)\n",
    "            sub_data = sub_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(sub_data)\n",
    "            loss = criterion_focal(out[mapping], sub_data.y[mapping])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * len(batch)\n",
    "            count += len(batch)\n",
    "            avg_loss = total_loss / count\n",
    "            pbar.set_postfix(batch_loss=f\"{loss.item():.4f}\", avg_loss=f\"{avg_loss:.4f}\")\n",
    "        print(f\"Fine-tune Epoch {epoch+1}/{num_epochs}, Focal Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            preds = out[data.val_mask].argmax(dim=1)\n",
    "            true = data.y[data.val_mask]\n",
    "            val_f1 = f1_score(true.cpu(), preds.cpu(), average=\"macro\")\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    return best_model_state\n",
    "\n",
    "def two_stage_train_model(data, model, optimizer, optimizer_ft, criterion_focal, criterion_contrast,\n",
    "                          pretrain_epochs, finetune_epochs, aug_method=\"feature\", aug_ratio=0.1,\n",
    "                          batch_size=64):\n",
    "    \"\"\"\n",
    "    两阶段训练：\n",
    "      第一阶段：预训练（仅用对比损失，mini-batch 方式）；\n",
    "      第二阶段：微调（仅用分类损失，mini-batch 方式）。\n",
    "    \"\"\"\n",
    "    print(\"========== 开始预训练阶段 ==========\")\n",
    "    best_pretrain_state = pretrain_model(data, model, optimizer, criterion_contrast,\n",
    "                                         num_epochs=pretrain_epochs,\n",
    "                                         aug_method=aug_method, aug_ratio=aug_ratio,\n",
    "                                         batch_size=batch_size)\n",
    "    model.load_state_dict(best_pretrain_state)\n",
    "\n",
    "    print(\"========== 开始微调阶段 ==========\")\n",
    "    best_finetune_state = fine_tune_model(data, model, optimizer_ft,\n",
    "                                          criterion_focal, num_epochs=finetune_epochs,\n",
    "                                          batch_size=batch_size)\n",
    "    return best_finetune_state\n",
    "\n",
    "#########################################\n",
    "# 5. 封装随机采样超参数组合的函数\n",
    "#########################################\n",
    "def get_continuous_candidates(start, stop, step, decimals):\n",
    "    \"\"\"\n",
    "    生成从 start 到 stop（含）之间，以 step 为步长的候选列表，并保留指定小数位数。\n",
    "    \"\"\"\n",
    "    num_steps = int((stop - start) / step) + 1\n",
    "    return [round(start + i * step, decimals) for i in range(num_steps)]\n",
    "\n",
    "def get_random_hyperparameter_combinations(n_iter):\n",
    "    \"\"\"\n",
    "    随机生成 n_iter 个超参数组合，每个组合包含：\n",
    "      (threshold, random_state, num_layers, hidden_channels, finetune_lr, pretrain_lr,\n",
    "       gamma, alpha_value, aug_method, aug_ratio, pretrain_epochs, temperature,\n",
    "       model_type, dropout_rate)\n",
    "    \"\"\"\n",
    "    # 离散变量候选列表\n",
    "    discrete_candidates = {\n",
    "        'random_state': list(range(0, 40, 10)),\n",
    "        'num_layers': [2, 3, 4],\n",
    "        'hidden_channels': list(range(20, 300, 20)),\n",
    "        'finetune_lr': [0.001],\n",
    "        'pretrain_lr': [0.0001, 0.00001, 0.000001],\n",
    "        'aug_method': [\"feature\", \"node_drop\", \"edge_drop\", \"edge_perturb\"],\n",
    "        'pretrain_epochs': [5],\n",
    "        'model_type': [\"GraphSAGE\", \"GAT\"],\n",
    "        'dropout_rate': [0.1, 0.2, 0.3]\n",
    "    }\n",
    "\n",
    "    # 连续变量候选区间及步长（注意：部分变量保留 2 位小数，其余保留 1 位小数）\n",
    "    continuous_candidates = {\n",
    "        'threshold': get_continuous_candidates(0.05, 0.2, 0.01, 2),\n",
    "        'gamma': get_continuous_candidates(1, 4, 0.1, 1),\n",
    "        # 'alpha_value': get_continuous_candidates(0.1, 0.9, 0.1, 1),\n",
    "        'alpha_value': [0.22, 0.78],\n",
    "        'aug_ratio': get_continuous_candidates(0.05, 0.25, 0.01, 2),\n",
    "        'temperature': get_continuous_candidates(0.05, 0.1, 0.01, 2)\n",
    "    }\n",
    "\n",
    "    combinations = []\n",
    "    for _ in range(n_iter):\n",
    "        # 随机采样连续变量\n",
    "        threshold   = random.choice(continuous_candidates['threshold'])\n",
    "        gamma       = random.choice(continuous_candidates['gamma'])\n",
    "        alpha_value = random.choice(continuous_candidates['alpha_value'])\n",
    "        aug_ratio   = random.choice(continuous_candidates['aug_ratio'])\n",
    "        temperature = random.choice(continuous_candidates['temperature'])\n",
    "        \n",
    "        # 随机采样离散变量\n",
    "        random_state    = random.choice(discrete_candidates['random_state'])\n",
    "        num_layers      = random.choice(discrete_candidates['num_layers'])\n",
    "        hidden_channels = random.choice(discrete_candidates['hidden_channels'])\n",
    "        finetune_lr     = random.choice(discrete_candidates['finetune_lr'])\n",
    "        pretrain_lr     = random.choice(discrete_candidates['pretrain_lr'])\n",
    "        aug_method      = random.choice(discrete_candidates['aug_method'])\n",
    "        pretrain_epochs = random.choice(discrete_candidates['pretrain_epochs'])\n",
    "        model_type      = random.choice(discrete_candidates['model_type'])\n",
    "        dropout_rate    = random.choice(discrete_candidates['dropout_rate'])\n",
    "        \n",
    "        # 构造超参数组合（顺序与注释中保持一致）\n",
    "        combination = (\n",
    "            threshold,      # 阈值\n",
    "            random_state,   # 随机种子\n",
    "            num_layers,     # 图卷积层数\n",
    "            hidden_channels,# 第一层隐藏单元数\n",
    "            finetune_lr,    # 微调学习率\n",
    "            pretrain_lr,    # 预训练学习率\n",
    "            gamma,          # gamma 参数\n",
    "            alpha_value,    # alpha 参数\n",
    "            aug_method,     # 增强方式\n",
    "            aug_ratio,      # 增强比例\n",
    "            pretrain_epochs,# 预训练轮数\n",
    "            temperature,    # 对比学习温度\n",
    "            model_type,     # 模型类型\n",
    "            dropout_rate    # dropout 概率\n",
    "        )\n",
    "        combinations.append(combination)\n",
    "        \n",
    "    return combinations\n",
    "\n",
    "#########################################\n",
    "# 6. 随机搜索超参数并评估模型\n",
    "#########################################\n",
    "def grid_search(X, y, train_mask, valid_mask, test_mask, n_iter):\n",
    "    best_acc = 0.0\n",
    "    best_overall_model_state = None\n",
    "    best_overall_params = None\n",
    "\n",
    "    print(\"Start random search with {} combinations...\".format(n_iter))\n",
    "    hyperparam_combos = get_random_hyperparameter_combinations(n_iter)\n",
    "    for i, (threshold, random_state, num_layers, hidden_channels, finetune_lr,\n",
    "            pretrain_lr, gamma, alpha_value, aug_method, aug_ratio, pretrain_epochs, temperature,\n",
    "            model_type, dropout_rate) in enumerate(hyperparam_combos):\n",
    "        print(f\"\\nTesting combination {i+1}: threshold={threshold:.4f}, random_state={random_state}, \"\n",
    "              f\"layers={num_layers}, hidden_channels={hidden_channels}, finetune_lr={finetune_lr}, \"\n",
    "              f\"pretrain_lr={pretrain_lr}, gamma={gamma:.4f}, alpha={alpha_value:.4f}, aug_method={aug_method}, \"\n",
    "              f\"aug_ratio={aug_ratio:.4f}, pretrain_epochs={pretrain_epochs}, temperature={temperature:.4f}, \"\n",
    "              f\"model_type={model_type}, dropout_rate={dropout_rate:.4f}\")\n",
    "\n",
    "        # 假设函数 adjacency_to_edge_index 已实现\n",
    "        edge_index = adjacency_to_edge_index(adjacency_matrix, threshold).to(device)\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float)\n",
    "        y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "        data = Data(x=X_tensor, y=y_tensor, edge_index=edge_index,\n",
    "                    train_mask=train_mask, val_mask=valid_mask, test_mask=test_mask).to(device)\n",
    "\n",
    "        # 根据 model_type 选择模型\n",
    "        if model_type == \"GraphSAGE\":\n",
    "            model = GraphSAGE(in_channels=X.shape[1], hidden_channels=hidden_channels,\n",
    "                              out_channels=len(np.unique(y)), num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
    "        elif model_type == \"GAT\":\n",
    "            model = GAT(in_channels=X.shape[1], hidden_channels=hidden_channels,\n",
    "                        out_channels=len(np.unique(y)), num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=pretrain_lr, weight_decay=5e-4)\n",
    "        optimizer_ft = torch.optim.Adam(model.parameters(), lr=finetune_lr, weight_decay=5e-4)\n",
    "\n",
    "        alpha_list = [1 - alpha_value, alpha_value]\n",
    "        alpha_tensor = torch.tensor(alpha_list, dtype=torch.float).to(device)\n",
    "        criterion_focal = FocalLoss(gamma=gamma, alpha=alpha_tensor, reduction=\"mean\")\n",
    "        criterion_contrast = SupConLoss(temperature=temperature)\n",
    "\n",
    "        best_model_epoch = two_stage_train_model(data, model, optimizer, optimizer_ft, criterion_focal,\n",
    "                                                 criterion_contrast, pretrain_epochs=pretrain_epochs, finetune_epochs=10,\n",
    "                                                 aug_method=aug_method, aug_ratio=aug_ratio, batch_size=4)\n",
    "        model.load_state_dict(best_model_epoch)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_out = model(data)\n",
    "            preds = test_out[data.test_mask].argmax(dim=1)\n",
    "            test_acc = accuracy_score(data.y[data.test_mask].cpu(), preds.cpu())\n",
    "        print(f\"Test Accuracy for current combination: {test_acc:.4f}\")\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_overall_model_state = best_model_epoch\n",
    "            best_overall_params = (threshold, random_state, num_layers, hidden_channels,\n",
    "                                   finetune_lr, pretrain_lr, gamma, alpha_value, aug_method, aug_ratio,\n",
    "                                   pretrain_epochs, temperature, model_type, dropout_rate)\n",
    "\n",
    "    return best_overall_params, best_overall_model_state\n",
    "\n",
    "#########################################\n",
    "# 7. 主程序：加载数据、随机搜索超参数、加载最佳模型并评估\n",
    "#########################################\n",
    "# 注意：此处假定 X, y, adjacency_matrix, train_mask, valid_mask, test_mask 已经提前加载好，\n",
    "# 且 edge_index 为形状 [2, num_edges] 的 torch.tensor 对象。\n",
    "\n",
    "best_params, best_model_state = grid_search(X, y, train_mask, valid_mask, test_mask, n_iter=1)\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n",
    "# 解包最佳超参数\n",
    "(threshold, random_state, num_layers, hidden_channels,\n",
    " finetune_lr, pretrain_lr, gamma, alpha_value, aug_method, aug_ratio,\n",
    " pretrain_epochs, temperature, model_type, dropout_rate) = best_params\n",
    "\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float).to(device)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.long).to(device)\n",
    "edge_index = adjacency_to_edge_index(adjacency_matrix, threshold).to(device)\n",
    "data = Data(x=X_tensor, y=y_tensor, edge_index=edge_index, train_mask=train_mask.to(device), val_mask=valid_mask.to(device), test_mask=test_mask.to(device))\n",
    "\n",
    "# 根据最终选出的模型类型构造模型\n",
    "if model_type == \"GraphSAGE\":\n",
    "    model = GraphSAGE(in_channels=X.shape[1], hidden_channels=hidden_channels,\n",
    "                      out_channels=len(np.unique(y)), num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
    "elif model_type == \"GAT\":\n",
    "    model = GAT(in_channels=X.shape[1], hidden_channels=hidden_channels,\n",
    "                out_channels=len(np.unique(y)), num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(data)\n",
    "    preds = test_out[data.test_mask].argmax(dim=1)\n",
    "    true_labels = data.y[data.test_mask]\n",
    "    report = classification_report(true_labels.cpu(), preds.cpu(), target_names=[\"Class 0\", \"Class 1\"], digits=4)\n",
    "    test_precision = precision_score(true_labels.cpu(), preds.cpu(), average=\"macro\")\n",
    "    test_recall = recall_score(true_labels.cpu(), preds.cpu(), average=\"macro\")\n",
    "    test_f1 = f1_score(true_labels.cpu(), preds.cpu(), average=\"macro\")\n",
    "    test_acc = accuracy_score(true_labels.cpu(), preds.cpu())\n",
    "    \n",
    "    print(\"\\nBest Model Classification Report on Test Set:\")\n",
    "    print(report)\n",
    "    print(\"Best Model Test Set Metrics:\")\n",
    "    print(f\"Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}, Accuracy: {test_acc:.4f}\")\n"
   ],
   "id": "c7e2562bc2ee8f3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start random search with 1 combinations...\n",
      "\n",
      "Testing combination 1: threshold=0.1400, random_state=20, layers=4, hidden_channels=60, finetune_lr=0.001, pretrain_lr=1e-06, gamma=3.1000, alpha=0.2200, aug_method=edge_perturb, aug_ratio=0.2500, pretrain_epochs=5, temperature=0.1000, model_type=GAT, dropout_rate=0.2000\n",
      "邻接矩阵转换完成！Edge index 维度: torch.Size([2, 60292392])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 13.42 GiB (GPU 0; 23.70 GiB total capacity; 11.96 GiB already allocated; 7.02 GiB free; 14.99 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 571\u001B[0m\n\u001B[1;32m    563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m best_overall_params, best_overall_model_state\n\u001B[1;32m    565\u001B[0m \u001B[38;5;66;03m#########################################\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;66;03m# 7. 主程序：加载数据、随机搜索超参数、加载最佳模型并评估\u001B[39;00m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;66;03m#########################################\u001B[39;00m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;66;03m# 注意：此处假定 X, y, adjacency_matrix, train_mask, valid_mask, test_mask 已经提前加载好，\u001B[39;00m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;66;03m# 且 edge_index 为形状 [2, num_edges] 的 torch.tensor 对象。\u001B[39;00m\n\u001B[0;32m--> 571\u001B[0m best_params, best_model_state \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mBest Hyperparameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, best_params)\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# 解包最佳超参数\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[6], line 546\u001B[0m, in \u001B[0;36mgrid_search\u001B[0;34m(X, y, train_mask, valid_mask, test_mask, n_iter)\u001B[0m\n\u001B[1;32m    543\u001B[0m criterion_focal \u001B[38;5;241m=\u001B[39m FocalLoss(gamma\u001B[38;5;241m=\u001B[39mgamma, alpha\u001B[38;5;241m=\u001B[39malpha_tensor, reduction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    544\u001B[0m criterion_contrast \u001B[38;5;241m=\u001B[39m SupConLoss(temperature\u001B[38;5;241m=\u001B[39mtemperature)\n\u001B[0;32m--> 546\u001B[0m best_model_epoch \u001B[38;5;241m=\u001B[39m \u001B[43mtwo_stage_train_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer_ft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_focal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mcriterion_contrast\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrain_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrain_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinetune_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    548\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43maug_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maug_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maug_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maug_ratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    549\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(best_model_epoch)\n\u001B[1;32m    550\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "Cell \u001B[0;32mIn[6], line 409\u001B[0m, in \u001B[0;36mtwo_stage_train_model\u001B[0;34m(data, model, optimizer, optimizer_ft, criterion_focal, criterion_contrast, pretrain_epochs, finetune_epochs, aug_method, aug_ratio, batch_size)\u001B[0m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;124;03m两阶段训练：\u001B[39;00m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;124;03m  第一阶段：预训练（仅用对比损失，mini-batch 方式）；\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;124;03m  第二阶段：微调（仅用分类损失，mini-batch 方式）。\u001B[39;00m\n\u001B[1;32m    407\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m========== 开始预训练阶段 ==========\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 409\u001B[0m best_pretrain_state \u001B[38;5;241m=\u001B[39m \u001B[43mpretrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_contrast\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrain_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43maug_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maug_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maug_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maug_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    413\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(best_pretrain_state)\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m========== 开始微调阶段 ==========\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[6], line 326\u001B[0m, in \u001B[0;36mpretrain_model\u001B[0;34m(data, model, optimizer, criterion_contrast, num_epochs, aug_method, aug_ratio, batch_size)\u001B[0m\n\u001B[1;32m    324\u001B[0m x_aug1, edge_index1 \u001B[38;5;241m=\u001B[39m augment_data(sub_data, aug_method, aug_ratio)\n\u001B[1;32m    325\u001B[0m x_aug2, edge_index2 \u001B[38;5;241m=\u001B[39m augment_data(sub_data, aug_method, aug_ratio)\n\u001B[0;32m--> 326\u001B[0m embedding_aug1 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_aug1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index1\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    327\u001B[0m embedding_aug2 \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode(x_aug2, edge_index2)\n\u001B[1;32m    328\u001B[0m target_emb1 \u001B[38;5;241m=\u001B[39m embedding_aug1[mapping]\n",
      "Cell \u001B[0;32mIn[6], line 109\u001B[0m, in \u001B[0;36mGAT.encode\u001B[0;34m(self, x, edge_index)\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"提取节点表示：依次通过 GAT 层、残差连接、ReLU 和 dropout\"\"\"\u001B[39;00m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m conv, res \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresiduals):\n\u001B[0;32m--> 109\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m     res_x \u001B[38;5;241m=\u001B[39m res(x)\n\u001B[1;32m    111\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(torch\u001B[38;5;241m.\u001B[39mrelu(out \u001B[38;5;241m+\u001B[39m res_x))\n",
      "File \u001B[0;32m~/anaconda3/envs/TabGNN/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_slow_forward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    888\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 889\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m itertools\u001B[38;5;241m.\u001B[39mchain(\n\u001B[1;32m    891\u001B[0m         _global_forward_hooks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[1;32m    892\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[1;32m    893\u001B[0m     hook_result \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, result)\n",
      "File \u001B[0;32m~/anaconda3/envs/TabGNN/lib/python3.9/site-packages/torch_geometric/nn/conv/gat_conv.py:152\u001B[0m, in \u001B[0;36mGATConv.forward\u001B[0;34m(self, x, edge_index, size, return_attention_weights)\u001B[0m\n\u001B[1;32m    149\u001B[0m         edge_index \u001B[38;5;241m=\u001B[39m set_diag(edge_index)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: OptPairTensor, alpha: OptPairTensor)\u001B[39;00m\n\u001B[0;32m--> 152\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_l\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_r\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m                     \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43malpha_l\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha_r\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    155\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/TabGNN/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:233\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[0;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;66;03m# Otherwise, run both functions in separation.\u001B[39;00m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(edge_index, Tensor) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuse:\n\u001B[0;32m--> 233\u001B[0m     coll_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__collect__\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__user_args__\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m     msg_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minspector\u001B[38;5;241m.\u001B[39mdistribute(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m, coll_dict)\n\u001B[1;32m    237\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmsg_kwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/TabGNN/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:157\u001B[0m, in \u001B[0;36mMessagePassing.__collect__\u001B[0;34m(self, args, edge_index, size, kwargs)\u001B[0m\n\u001B[1;32m    155\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, Tensor):\n\u001B[1;32m    156\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__set_size__(size, dim, data)\n\u001B[0;32m--> 157\u001B[0m             data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__lift__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_j\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    160\u001B[0m         out[arg] \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(edge_index, Tensor):\n",
      "File \u001B[0;32m~/anaconda3/envs/TabGNN/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:127\u001B[0m, in \u001B[0;36mMessagePassing.__lift__\u001B[0;34m(self, src, edge_index, dim)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(edge_index, Tensor):\n\u001B[1;32m    126\u001B[0m     index \u001B[38;5;241m=\u001B[39m edge_index[dim]\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msrc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex_select\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(edge_index, SparseTensor):\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 13.42 GiB (GPU 0; 23.70 GiB total capacity; 11.96 GiB already allocated; 7.02 GiB free; 14.99 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Best Hyperparameters: (0.05, 10, 3, 120, 0.001, 1e-06, 3.9, 0.4, 'feature', 0.16, 1, 0.09, 'GraphSAGE', 0.1)\n",
    "邻接矩阵转换完成！\n",
    "Edge index 维度: torch.Size([2, 6248838])\n",
    "\n",
    "Best Model Classification Report on Test Set:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0     0.7788    1.0000    0.8757      4673\n",
    "     Class 1     0.0000    0.0000    0.0000      1327\n",
    "\n",
    "    accuracy                         0.7788      6000\n",
    "   macro avg     0.3894    0.5000    0.4378      6000\n",
    "weighted avg     0.6066    0.7788    0.6820      6000Fine-tune Epoch: 27, Focal Loss: 539.1759\n",
    "Fine-tune Epoch: 28, Focal Loss: 528.0142\n",
    "Fine-tune Epoch: 29, Focal Loss: 527.8759\n",
    "Test Accuracy for current combination: 0.7662\n",
    "\n",
    "Best Hyperparameters: (0.06, 30, 3, 40, 1e-06, 0.001, 3.0, 0.3, 'edge_perturb', 0.22, 1, 0.28, 'GraphSAGE', 0.2)\n",
    "邻接矩阵转换完成！\n",
    "Edge index 维度: torch.Size([2, 4800498])\n",
    "\n",
    "Best Model Classification Report on Test Set:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0     0.7829    0.9683    0.8658      4673\n",
    "     Class 1     0.3273    0.0543    0.0931      1327\n",
    "\n",
    "    accuracy                         0.7662      6000\n",
    "   macro avg     0.5551    0.5113    0.4794      6000\n",
    "weighted avg     0.6821    0.7662    0.6949      6000\n",
    "\n",
    "Best Model Test Set Metrics:\n",
    "Precision: 0.5551, Recall: 0.5113, F1: 0.4794, Accuracy: 0.7662\n",
    "\n",
    "\n",
    "Best Hyperparameters: (0.03, 0, 3, 40, 0.001, 1e-06, 2.3, 0.5, 'node_drop', 0.23, 1, 0.27, 'GAT', 0.1)\n",
    "邻接矩阵转换完成！\n",
    "Edge index 维度: torch.Size([2, 11802304])\n",
    "\n",
    "Best Model Classification Report on Test Set:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0     0.7788    1.0000    0.8757      4673\n",
    "     Class 1     0.0000    0.0000    0.0000      1327\n",
    "\n",
    "    accuracy                         0.7788      6000\n",
    "   macro avg     0.3894    0.5000    0.4378      6000\n",
    "weighted avg     0.6066    0.7788    0.6820      6000\n",
    "\n",
    "Best Model Test Set Metrics:\n",
    "Precision: 0.3894, Recall: 0.5000, F1: 0.4378, Accuracy: 0.7788\n",
    "\n",
    "Best Hyperparameters: (0.05, 0, 4, 80, 0.0001, 1e-05, 3.8, 0.4, 'edge_perturb', 0.12, 1, 0.16, 'GraphSAGE', 0)\n",
    "邻接矩阵转换完成！\n",
    "Edge index 维度: torch.Size([2, 6248838])\n",
    "\n",
    "Best Model Classification Report on Test Set:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0     0.7788    0.9998    0.8756      4673\n",
    "     Class 1     0.0000    0.0000    0.0000      1327\n",
    "\n",
    "    accuracy                         0.7787      6000\n",
    "   macro avg     0.3894    0.4999    0.4378      6000\n",
    "weighted avg     0.6066    0.7787    0.6819      6000\n",
    "\n",
    "邻接矩阵转换完成！\n",
    "Edge index 维度: torch.Size([2, 4800498])\n",
    "Best Model Classification Report on Test Set:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "     Class 0     0.7812    0.9863    0.8718      4673\n",
    "     Class 1     0.3600    0.0271    0.0505      1327\n",
    "\n",
    "    accuracy                         0.7742      6000\n",
    "   macro avg     0.5706    0.5067    0.4611      6000\n",
    "weighted avg     0.6880    0.7742    0.6902      6000\n",
    "\n",
    "Best Model Test Set Metrics:\n",
    "Precision: 0.5706, Recall: 0.5067, F1: 0.4611, Accuracy: 0.7742"
   ],
   "id": "15a1541c19ddec17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "### 可能的采样优化 交叉shang损失",
   "id": "4c72dfd730487c8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T22:08:47.002407Z",
     "start_time": "2025-02-10T21:50:50.192128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv, GATConv\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from tqdm import tqdm  # 用于显示训练进度\n",
    "\n",
    "# 假设设备定义如下\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#########################################\n",
    "# 1. 定义模型\n",
    "#########################################\n",
    "# GraphSAGE 模型（包含残差结构和 dropout，每层隐藏单元数递减至上一层的3/4）\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout_rate=0.5):\n",
    "        \"\"\"\n",
    "        参数说明：\n",
    "          in_channels: 输入特征维度\n",
    "          hidden_channels: 第一层的隐藏单元数\n",
    "          out_channels: 输出类别数\n",
    "          num_layers: 图卷积层的总层数（至少为 1）\n",
    "          dropout_rate: dropout 概率\n",
    "        \"\"\"\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.residuals = torch.nn.ModuleList()\n",
    "        # 第一层：从 in_channels 到 hidden_channels\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        if in_channels != hidden_channels:\n",
    "            self.residuals.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        else:\n",
    "            self.residuals.append(torch.nn.Identity())\n",
    "        current_hidden = hidden_channels\n",
    "        # 后续每一层的隐藏单元数为上一层的 3/4（向下取整，最小为 1）\n",
    "        for _ in range(num_layers - 1):\n",
    "            next_hidden = max(1, int(current_hidden * 3 / 4))\n",
    "            self.convs.append(SAGEConv(current_hidden, next_hidden))\n",
    "            if current_hidden != next_hidden:\n",
    "                self.residuals.append(torch.nn.Linear(current_hidden, next_hidden))\n",
    "            else:\n",
    "                self.residuals.append(torch.nn.Identity())\n",
    "            current_hidden = next_hidden\n",
    "        # 全连接层：将最后一层的隐藏向量映射到输出类别\n",
    "        self.fc = torch.nn.Linear(current_hidden, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        \"\"\"提取节点表示：依次通过图卷积层、残差连接、ReLU 和 dropout（适用于全图或子图）\"\"\"\n",
    "        for conv, res in zip(self.convs, self.residuals):\n",
    "            out = conv(x, edge_index)\n",
    "            res_x = res(x)\n",
    "            x = self.dropout(torch.relu(out + res_x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.encode(data.x, data.edge_index)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# GAT 模型（包含残差结构和 dropout，每层隐藏单元数递减至上一层的3/4）\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2, dropout_rate=0.5, heads=1, concat=True):\n",
    "        \"\"\"\n",
    "        参数说明：\n",
    "          in_channels: 输入特征维度\n",
    "          hidden_channels: 第一层的隐藏单元数\n",
    "          out_channels: 输出类别数\n",
    "          num_layers: 图卷积层的总层数（至少为 1）\n",
    "          dropout_rate: dropout 概率（同时用于 GATConv 内部 dropout）\n",
    "          heads: 注意力头的数量\n",
    "          concat: 是否拼接多头输出（True）或取平均（False）\n",
    "        \"\"\"\n",
    "        super(GAT, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.residuals = torch.nn.ModuleList()\n",
    "        # 第一层\n",
    "        self.convs.append(GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout_rate, concat=concat))\n",
    "        out_dim = hidden_channels * heads if concat else hidden_channels\n",
    "        if in_channels != out_dim:\n",
    "            self.residuals.append(torch.nn.Linear(in_channels, out_dim))\n",
    "        else:\n",
    "            self.residuals.append(torch.nn.Identity())\n",
    "        current_dim = out_dim\n",
    "        # 后续层\n",
    "        for _ in range(num_layers - 1):\n",
    "            next_hidden = max(1, int(current_dim * 3 / 4))\n",
    "            self.convs.append(GATConv(current_dim, next_hidden, heads=heads, dropout=dropout_rate, concat=concat))\n",
    "            new_out_dim = next_hidden * heads if concat else next_hidden\n",
    "            if current_dim != new_out_dim:\n",
    "                self.residuals.append(torch.nn.Linear(current_dim, new_out_dim))\n",
    "            else:\n",
    "                self.residuals.append(torch.nn.Identity())\n",
    "            current_dim = new_out_dim\n",
    "        self.fc = torch.nn.Linear(current_dim, out_channels)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        \"\"\"提取节点表示：依次通过 GAT 层、残差连接、ReLU 和 dropout\"\"\"\n",
    "        for conv, res in zip(self.convs, self.residuals):\n",
    "            out = conv(x, edge_index)\n",
    "            res_x = res(x)\n",
    "            x = self.dropout(torch.relu(out + res_x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.encode(data.x, data.edge_index)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "#########################################\n",
    "# 2. 定义损失函数\n",
    "#########################################\n",
    "# 下面的 FocalLoss 类保留不动，但在微调阶段我们将换用普通的交叉熵损失，\n",
    "# 因此后续训练中不会使用该类。\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, reduction=\"mean\"):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha  \n",
    "        self.reduction = reduction\n",
    "        self.ce = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (list, np.ndarray)):\n",
    "                alpha = inputs.new_tensor(self.alpha)\n",
    "            else:\n",
    "                alpha = self.alpha\n",
    "            at = alpha.gather(0, targets.data)\n",
    "            ce_loss = at * ce_loss\n",
    "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "        return focal_loss.mean() if self.reduction == \"mean\" else focal_loss.sum()\n",
    "\n",
    "# 修改后的普通对比学习损失（不使用 mask）\n",
    "class SupConLoss(torch.nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            temperature: 温度参数\n",
    "        \"\"\"\n",
    "        super(SupConLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: [batch_size, n_views, feature_dim]\n",
    "                      要求每个样本至少有两个视图，视图之间互为正样本，其余样本均为负样本。\n",
    "        Returns:\n",
    "            对比损失（InfoNCE Loss）\n",
    "        \"\"\"\n",
    "        device = features.device\n",
    "        if len(features.shape) < 3:\n",
    "            raise ValueError('`features` 需要形状为 [batch_size, n_views, feature_dim]')\n",
    "        batch_size, n_views, feature_dim = features.shape\n",
    "\n",
    "        # 将多个视图拼接为 [batch_size*n_views, feature_dim]\n",
    "        features = features.view(batch_size * n_views, feature_dim)\n",
    "        # 对每个特征进行 L2 归一化\n",
    "        features = torch.nn.functional.normalize(features, p=2, dim=1)\n",
    "\n",
    "        # 计算相似度矩阵，形状 [batch_size*n_views, batch_size*n_views]\n",
    "        similarity_matrix = torch.matmul(features, features.T) / self.temperature\n",
    "\n",
    "        # 构造正样本掩码：同一原始样本（即同一 batch 中的不同视图）的两两之间为正样本\n",
    "        labels = torch.arange(batch_size, device=device).repeat_interleave(n_views)\n",
    "        mask = torch.eq(labels.unsqueeze(1), labels.unsqueeze(0)).float()\n",
    "        # 去除自身对比（对角线置 0）\n",
    "        self_mask = torch.eye(mask.shape[0], device=device)\n",
    "        mask = mask - self_mask\n",
    "\n",
    "        # 计算 exp(similarity)\n",
    "        exp_sim = torch.exp(similarity_matrix) * (1 - self_mask)\n",
    "        # 对每个 anchor，分母为除自身外所有样本的 exp(sim)\n",
    "        denom = exp_sim.sum(dim=1, keepdim=True) + 1e-8\n",
    "\n",
    "        # 计算仅正样本对的对数概率\n",
    "        log_prob = similarity_matrix - torch.log(denom)\n",
    "        numerator = (mask * log_prob).sum(dim=1)\n",
    "        # 正样本个数（防止除 0）\n",
    "        pos_count = mask.sum(dim=1) + 1e-8\n",
    "        loss = - (numerator / pos_count)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "\n",
    "#########################################\n",
    "# 3. 数据增强方法\n",
    "#########################################\n",
    "# 原始的特征扰动（用于 \"feature\" 增强方式）\n",
    "def perturb_features(features, noise_level=0.1):\n",
    "    \"\"\"对特征进行扰动，生成增强视图\"\"\"\n",
    "    noise = torch.randn_like(features) * noise_level\n",
    "    return features + noise\n",
    "\n",
    "# 节点丢弃\n",
    "def augment_node_drop(features, edge_index, drop_prob=0.1):\n",
    "    \"\"\"\n",
    "    节点丢弃：以一定概率丢弃节点（将被丢弃节点的特征置零，\n",
    "    同时删除其相关边，但保持节点的序号不变）。\n",
    "    \"\"\"\n",
    "    if isinstance(drop_prob, (list, tuple)):\n",
    "        drop_prob = float(drop_prob[0])\n",
    "    num_nodes = features.shape[0]\n",
    "    keep_mask = (torch.rand(num_nodes, device=features.device) > drop_prob)\n",
    "    features_aug = features * keep_mask.unsqueeze(1).float()\n",
    "    src, dst = edge_index\n",
    "    valid_edge_mask = keep_mask[src] & keep_mask[dst]\n",
    "    edge_index_aug = edge_index[:, valid_edge_mask]\n",
    "    return features_aug, edge_index_aug\n",
    "\n",
    "# 边丢弃\n",
    "def augment_edge_drop(features, edge_index, drop_prob=0.1):\n",
    "    \"\"\"\n",
    "    边丢弃：以一定概率删除边，但保留所有节点和原始特征。\n",
    "    \"\"\"\n",
    "    if isinstance(drop_prob, (list, tuple)):\n",
    "        drop_prob = float(drop_prob[0])\n",
    "    num_edges = edge_index.shape[1]\n",
    "    mask = (torch.rand(num_edges, device=edge_index.device) > drop_prob)\n",
    "    edge_index_aug = edge_index[:, mask]\n",
    "    return features, edge_index_aug\n",
    "\n",
    "# 边扰动\n",
    "def augment_edge_perturb(features, edge_index, drop_prob=0.1):\n",
    "    \"\"\"\n",
    "    边扰动：先以一定概率删除部分边，再随机添加一些新的边，\n",
    "    添加的新边数量与被删除边的数量相当。\n",
    "    \"\"\"\n",
    "    if isinstance(drop_prob, (list, tuple)):\n",
    "        drop_prob = float(drop_prob[0])\n",
    "    num_edges = edge_index.shape[1]\n",
    "    num_nodes = features.shape[0]\n",
    "    mask = (torch.rand(num_edges, device=edge_index.device) > drop_prob)\n",
    "    edge_index_dropped = edge_index[:, mask]\n",
    "    num_dropped = num_edges - mask.sum().item()\n",
    "    if num_dropped > 0:\n",
    "        new_edges = torch.randint(0, num_nodes, (2, num_dropped), device=features.device)\n",
    "        edge_index_aug = torch.cat([edge_index_dropped, new_edges], dim=1)\n",
    "    else:\n",
    "        edge_index_aug = edge_index_dropped\n",
    "    return features, edge_index_aug\n",
    "\n",
    "def augment_data(data, aug_method=\"feature\", aug_ratio=0.1):\n",
    "    \"\"\"\n",
    "    根据指定的增强方式对图数据进行增强，返回增强后的节点特征和 edge_index。\n",
    "    参数:\n",
    "      aug_method: \"feature\"（特征扰动）, \"node_drop\", \"edge_drop\", \"edge_perturb\"\n",
    "      aug_ratio: 控制增强强度（例如噪声水平或丢弃比例）\n",
    "    \"\"\"\n",
    "    if aug_method == \"feature\":\n",
    "        x_aug = perturb_features(data.x, noise_level=aug_ratio)\n",
    "        edge_index_aug = data.edge_index  # 图结构不变\n",
    "        return x_aug, edge_index_aug\n",
    "    elif aug_method == \"node_drop\":\n",
    "        return augment_node_drop(data.x, data.edge_index, drop_prob=aug_ratio)\n",
    "    elif aug_method == \"edge_drop\":\n",
    "        return augment_edge_drop(data.x, data.edge_index, drop_prob=aug_ratio)\n",
    "    elif aug_method == \"edge_perturb\":\n",
    "        return augment_edge_perturb(data.x, data.edge_index, drop_prob=aug_ratio)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown augmentation method: {aug_method}\")\n",
    "\n",
    "#########################################\n",
    "# 3.1 辅助函数：提取 mini-batch 子图\n",
    "#########################################\n",
    "def get_mini_batch_data(data, batch_node_idx, num_hops):\n",
    "    \"\"\"\n",
    "    对单图中一小批节点（batch_node_idx）提取 k-hop 子图。\n",
    "    使用 torch_geometric.utils.k_hop_subgraph 进行子图提取，并 relabel 节点。\n",
    "    返回：\n",
    "      sub_data: 包含子图的 Data 对象（x, edge_index, y 以及 mask 可选）\n",
    "      mapping: 一个长整型张量，指示子图中哪一部分对应原始 batch_node_idx（目标节点在子图中的索引）\n",
    "    \"\"\"\n",
    "    # k_hop_subgraph 返回：(subset, sub_edge_index, mapping, edge_mask)\n",
    "    subset, sub_edge_index, mapping, _ = k_hop_subgraph(\n",
    "        node_idx=batch_node_idx, num_hops=num_hops, edge_index=data.edge_index, relabel_nodes=True)\n",
    "    sub_data = Data(x=data.x[subset], edge_index=sub_edge_index, y=data.y[subset])\n",
    "    # 如果原始 data 定义了 train/val/test mask，则在子图中也保留（注意：mask 按 subset 索引提取）\n",
    "    if hasattr(data, 'train_mask'):\n",
    "        sub_data.train_mask = data.train_mask[subset]\n",
    "    if hasattr(data, 'val_mask'):\n",
    "        sub_data.val_mask = data.val_mask[subset]\n",
    "    if hasattr(data, 'test_mask'):\n",
    "        sub_data.test_mask = data.test_mask[subset]\n",
    "    return sub_data, mapping\n",
    "\n",
    "#########################################\n",
    "# 4. 训练函数（预训练 + 微调）——mini-batch 版（基于 k_hop_subgraph）\n",
    "#########################################\n",
    "def pretrain_model(data, model, optimizer, criterion_contrast, num_epochs=200, aug_method=\"feature\", aug_ratio=0.1, batch_size=64):\n",
    "    \"\"\"\n",
    "    预训练阶段：仅使用对比损失训练模型（不计算交叉熵损失）。\n",
    "    采用 mini-batch 方式，先对训练集中的一批目标节点提取 k-hop 子图，\n",
    "    再对该子图进行数据增强生成两视图，最后计算对比损失（仅对 batch 中的目标节点计算）。\n",
    "    使用 tqdm 显示每个 epoch 以及 batch 的进度和损失。\n",
    "    \"\"\"\n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1).tolist()\n",
    "    num_hops = len(model.convs)  # 以模型层数作为子图的 hop 数\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "        loader = DataLoader(train_idx, batch_size=batch_size, shuffle=True)\n",
    "        # 使用 tqdm 包裹 batch 迭代\n",
    "        pbar = tqdm(loader, desc=f\"Pretrain Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for batch in pbar:\n",
    "            batch = batch.clone().detach().to(device)\n",
    "            sub_data, mapping = get_mini_batch_data(data, batch, num_hops)\n",
    "            sub_data = sub_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_aug1, edge_index1 = augment_data(sub_data, aug_method, aug_ratio)\n",
    "            x_aug2, edge_index2 = augment_data(sub_data, aug_method, aug_ratio)\n",
    "            embedding_aug1 = model.encode(x_aug1, edge_index1)\n",
    "            embedding_aug2 = model.encode(x_aug2, edge_index2)\n",
    "            target_emb1 = embedding_aug1[mapping]\n",
    "            target_emb2 = embedding_aug2[mapping]\n",
    "            features_aug = torch.stack([target_emb1, target_emb2], dim=1)\n",
    "            loss = criterion_contrast(features_aug)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * len(batch)\n",
    "            count += len(batch)\n",
    "            avg_loss = total_loss / count\n",
    "            pbar.set_postfix(batch_loss=f\"{loss.item():.4f}\", avg_loss=f\"{avg_loss:.4f}\")\n",
    "        print(f\"Pretrain Epoch {epoch+1}/{num_epochs}, Contrast Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            preds = out[data.val_mask].argmax(dim=1)\n",
    "            true = data.y[data.val_mask]\n",
    "            val_f1 = f1_score(true.cpu(), preds.cpu(), average=\"macro\")\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    return best_model_state\n",
    "\n",
    "def fine_tune_model(data, model, optimizer, criterion_ce, num_epochs=50, batch_size=64):\n",
    "    \"\"\"\n",
    "    微调阶段：仅使用交叉熵损失进行训练（不计算对比损失）。\n",
    "    同样采用 mini-batch（基于 k_hop 子图）方式训练，损失仅在目标节点上计算。\n",
    "    使用 tqdm 实时显示每个 epoch 与 batch 的训练进度和损失信息。\n",
    "    \"\"\"\n",
    "    best_f1 = 0.0\n",
    "    best_model_state = None\n",
    "    train_idx = data.train_mask.nonzero(as_tuple=False).view(-1).tolist()\n",
    "    num_hops = len(model.convs)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        count = 0\n",
    "        loader = DataLoader(train_idx, batch_size=batch_size, shuffle=True)\n",
    "        pbar = tqdm(loader, desc=f\"Fine-tune Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        for batch in pbar:\n",
    "            batch = batch.clone().detach().to(device)\n",
    "            sub_data, mapping = get_mini_batch_data(data, batch, num_hops)\n",
    "            sub_data = sub_data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(sub_data)\n",
    "            loss = criterion_ce(out[mapping], sub_data.y[mapping])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * len(batch)\n",
    "            count += len(batch)\n",
    "            avg_loss = total_loss / count\n",
    "            pbar.set_postfix(batch_loss=f\"{loss.item():.4f}\", avg_loss=f\"{avg_loss:.4f}\")\n",
    "        print(f\"Fine-tune Epoch {epoch+1}/{num_epochs}, CE Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            preds = out[data.val_mask].argmax(dim=1)\n",
    "            true = data.y[data.val_mask]\n",
    "            val_f1 = f1_score(true.cpu(), preds.cpu(), average=\"macro\")\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    return best_model_state\n",
    "\n",
    "def two_stage_train_model(data, model, optimizer, optimizer_ft, criterion_ce, criterion_contrast,\n",
    "                          pretrain_epochs, finetune_epochs, aug_method=\"feature\", aug_ratio=0.1,\n",
    "                          batch_size=64):\n",
    "    \"\"\"\n",
    "    两阶段训练：\n",
    "      第一阶段：预训练（仅用对比损失，mini-batch 方式）；\n",
    "      第二阶段：微调（仅用交叉熵损失，mini-batch 方式）。\n",
    "    \"\"\"\n",
    "    print(\"========== 开始预训练阶段 ==========\")\n",
    "    best_pretrain_state = pretrain_model(data, model, optimizer, criterion_contrast,\n",
    "                                         num_epochs=pretrain_epochs,\n",
    "                                         aug_method=aug_method, aug_ratio=aug_ratio,\n",
    "                                         batch_size=batch_size)\n",
    "    model.load_state_dict(best_pretrain_state)\n",
    "\n",
    "    print(\"========== 开始微调阶段 ==========\")\n",
    "    best_finetune_state = fine_tune_model(data, model, optimizer_ft,\n",
    "                                          criterion_ce, num_epochs=finetune_epochs,\n",
    "                                          batch_size=batch_size)\n",
    "    return best_finetune_state\n",
    "\n",
    "#########################################\n",
    "# 5. 封装随机采样超参数组合的函数\n",
    "#########################################\n",
    "def get_continuous_candidates(start, stop, step, decimals):\n",
    "    \"\"\"\n",
    "    生成从 start 到 stop（含）之间，以 step 为步长的候选列表，并保留指定小数位数。\n",
    "    \"\"\"\n",
    "    num_steps = int((stop - start) / step) + 1\n",
    "    return [round(start + i * step, decimals) for i in range(num_steps)]\n",
    "\n",
    "def get_random_hyperparameter_combinations(n_iter):\n",
    "    \"\"\"\n",
    "    随机生成 n_iter 个超参数组合，每个组合包含：\n",
    "      (threshold, random_state, num_layers, hidden_channels, finetune_lr, pretrain_lr,\n",
    "       gamma, alpha_value, aug_method, aug_ratio, pretrain_epochs, temperature,\n",
    "       model_type, dropout_rate)\n",
    "    \"\"\"\n",
    "    # 离散变量候选列表\n",
    "    discrete_candidates = {\n",
    "        'random_state': list(range(0, 40, 10)),\n",
    "        'num_layers': [2, 3, 4],\n",
    "        'hidden_channels': list(range(20, 300, 20)),\n",
    "        'finetune_lr': [0.001],\n",
    "        'pretrain_lr': [0.0001, 0.00001, 0.000001],\n",
    "        'aug_method': [\"feature\", \"node_drop\", \"edge_drop\", \"edge_perturb\"],\n",
    "        'pretrain_epochs': [5],\n",
    "        'model_type': [\"GraphSAGE\", \"GAT\"],\n",
    "        'dropout_rate': [0.1, 0.2, 0.3]\n",
    "    }\n",
    "\n",
    "    # 连续变量候选区间及步长（注意：部分变量保留 2 位小数，其余保留 1 位小数）\n",
    "    continuous_candidates = {\n",
    "        'threshold': get_continuous_candidates(0.05, 0.2, 0.01, 2),\n",
    "        'gamma': get_continuous_candidates(1, 4, 0.1, 1),\n",
    "        # 'alpha_value': get_continuous_candidates(0.1, 0.9, 0.1, 1),\n",
    "        'alpha_value': [0.22, 0.78],\n",
    "        'aug_ratio': get_continuous_candidates(0.05, 0.25, 0.01, 2),\n",
    "        'temperature': get_continuous_candidates(0.05, 0.1, 0.01, 2)\n",
    "    }\n",
    "\n",
    "    combinations = []\n",
    "    for _ in range(n_iter):\n",
    "        # 随机采样连续变量\n",
    "        threshold   = random.choice(continuous_candidates['threshold'])\n",
    "        gamma       = random.choice(continuous_candidates['gamma'])\n",
    "        alpha_value = random.choice(continuous_candidates['alpha_value'])\n",
    "        aug_ratio   = random.choice(continuous_candidates['aug_ratio'])\n",
    "        temperature = random.choice(continuous_candidates['temperature'])\n",
    "        \n",
    "        # 随机采样离散变量\n",
    "        random_state    = random.choice(discrete_candidates['random_state'])\n",
    "        num_layers      = random.choice(discrete_candidates['num_layers'])\n",
    "        hidden_channels = random.choice(discrete_candidates['hidden_channels'])\n",
    "        finetune_lr     = random.choice(discrete_candidates['finetune_lr'])\n",
    "        pretrain_lr     = random.choice(discrete_candidates['pretrain_lr'])\n",
    "        aug_method      = random.choice(discrete_candidates['aug_method'])\n",
    "        pretrain_epochs = random.choice(discrete_candidates['pretrain_epochs'])\n",
    "        model_type      = random.choice(discrete_candidates['model_type'])\n",
    "        dropout_rate    = random.choice(discrete_candidates['dropout_rate'])\n",
    "        \n",
    "        # 构造超参数组合（顺序与注释中保持一致）\n",
    "        combination = (\n",
    "            threshold,      # 阈值\n",
    "            random_state,   # 随机种子\n",
    "            num_layers,     # 图卷积层数\n",
    "            hidden_channels,# 第一层隐藏单元数\n",
    "            finetune_lr,    # 微调学习率\n",
    "            pretrain_lr,    # 预训练学习率\n",
    "            gamma,          # gamma 参数\n",
    "            alpha_value,    # alpha 参数\n",
    "            aug_method,     # 增强方式\n",
    "            aug_ratio,      # 增强比例\n",
    "            pretrain_epochs,# 预训练轮数\n",
    "            temperature,    # 对比学习温度\n",
    "            model_type,     # 模型类型\n",
    "            dropout_rate    # dropout 概率\n",
    "        )\n",
    "        combinations.append(combination)\n",
    "        \n",
    "    return combinations\n",
    "\n",
    "#########################################\n",
    "# 6. 随机搜索超参数并评估模型\n",
    "#########################################\n",
    "def grid_search(X, y, train_mask, valid_mask, test_mask, n_iter):\n",
    "    best_acc = 0.0\n",
    "    best_overall_model_state = None\n",
    "    best_overall_params = None\n",
    "\n",
    "    print(\"Start random search with {} combinations...\".format(n_iter))\n",
    "    hyperparam_combos = get_random_hyperparameter_combinations(n_iter)\n",
    "    for i, (threshold, random_state, num_layers, hidden_channels, finetune_lr,\n",
    "            pretrain_lr, gamma, alpha_value, aug_method, aug_ratio, pretrain_epochs, temperature,\n",
    "            model_type, dropout_rate) in enumerate(hyperparam_combos):\n",
    "        print(f\"\\nTesting combination {i+1}: threshold={threshold:.4f}, random_state={random_state}, \"\n",
    "              f\"layers={num_layers}, hidden_channels={hidden_channels}, finetune_lr={finetune_lr}, \"\n",
    "              f\"pretrain_lr={pretrain_lr}, gamma={gamma:.4f}, alpha={alpha_value:.4f}, aug_method={aug_method}, \"\n",
    "              f\"aug_ratio={aug_ratio:.4f}, pretrain_epochs={pretrain_epochs}, temperature={temperature:.4f}, \"\n",
    "              f\"model_type={model_type}, dropout_rate={dropout_rate:.4f}\")\n",
    "\n",
    "        # 假设函数 adjacency_to_edge_index 已实现\n",
    "        edge_index = adjacency_to_edge_index(adjacency_matrix, threshold).to(device)\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float)\n",
    "        y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "        data = Data(x=X_tensor, y=y_tensor, edge_index=edge_index,\n",
    "                    train_mask=train_mask, val_mask=valid_mask, test_mask=test_mask).to(device)\n",
    "\n",
    "        # 根据 model_type 选择模型\n",
    "        if model_type == \"GraphSAGE\":\n",
    "            model = GraphSAGE(in_channels=X.shape[1], hidden_channels=hidden_channels,\n",
    "                              out_channels=len(np.unique(y)), num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
    "        elif model_type == \"GAT\":\n",
    "            model = GAT(in_channels=X.shape[1], hidden_channels=hidden_channels,\n",
    "                        out_channels=len(np.unique(y)), num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=pretrain_lr, weight_decay=5e-4)\n",
    "        optimizer_ft = torch.optim.Adam(model.parameters(), lr=finetune_lr, weight_decay=5e-4)\n",
    "\n",
    "        # 使用普通的交叉熵损失替代 FocalLoss\n",
    "        criterion_ce = torch.nn.CrossEntropyLoss()\n",
    "        criterion_contrast = SupConLoss(temperature=temperature)\n",
    "\n",
    "        best_model_epoch = two_stage_train_model(data, model, optimizer, optimizer_ft, criterion_ce,\n",
    "                                                 criterion_contrast, pretrain_epochs=pretrain_epochs, finetune_epochs=10,\n",
    "                                                 aug_method=aug_method, aug_ratio=aug_ratio, batch_size=128)\n",
    "        model.load_state_dict(best_model_epoch)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_out = model(data)\n",
    "            preds = test_out[data.test_mask].argmax(dim=1)\n",
    "            test_acc = accuracy_score(data.y[data.test_mask].cpu(), preds.cpu())\n",
    "        print(f\"Test Accuracy for current combination: {test_acc:.4f}\")\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_overall_model_state = best_model_epoch\n",
    "            best_overall_params = (threshold, random_state, num_layers, hidden_channels,\n",
    "                                   finetune_lr, pretrain_lr, gamma, alpha_value, aug_method, aug_ratio,\n",
    "                                   pretrain_epochs, temperature, model_type, dropout_rate)\n",
    "\n",
    "    return best_overall_params, best_overall_model_state\n",
    "\n",
    "#########################################\n",
    "# 7. 主程序：加载数据、随机搜索超参数、加载最佳模型并评估\n",
    "#########################################\n",
    "# 注意：此处假定 X, y, adjacency_matrix, train_mask, valid_mask, test_mask 已经提前加载好，\n",
    "# 且 edge_index 为形状 [2, num_edges] 的 torch.tensor 对象。\n",
    "\n",
    "best_params, best_model_state = grid_search(X, y, train_mask, valid_mask, test_mask, n_iter=100)\n",
    "print(\"\\nBest Hyperparameters:\", best_params)\n",
    "\n",
    "# 解包最佳超参数\n",
    "(threshold, random_state, num_layers, hidden_channels,\n",
    " finetune_lr, pretrain_lr, gamma, alpha_value, aug_method, aug_ratio,\n",
    " pretrain_epochs, temperature, model_type, dropout_rate) = best_params\n",
    "\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float).to(device)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.long).to(device)\n",
    "edge_index = adjacency_to_edge_index(adjacency_matrix, threshold).to(device)\n",
    "data = Data(x=X_tensor, y=y_tensor, edge_index=edge_index, train_mask=train_mask.to(device), val_mask=valid_mask.to(device), test_mask=test_mask.to(device))\n",
    "\n",
    "# 根据最终选出的模型类型构造模型\n",
    "if model_type == \"GraphSAGE\":\n",
    "    model = GraphSAGE(in_channels=X.shape[1], hidden_channels=hidden_channels,\n",
    "                      out_channels=len(np.unique(y)), num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
    "elif model_type == \"GAT\":\n",
    "    model = GAT(in_channels=X.shape[1], hidden_channels=hidden_channels,\n",
    "                out_channels=len(np.unique(y)), num_layers=num_layers, dropout_rate=dropout_rate).to(device)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_out = model(data)\n",
    "    preds = test_out[data.test_mask].argmax(dim=1)\n",
    "    true_labels = data.y[data.test_mask]\n",
    "    report = classification_report(true_labels.cpu(), preds.cpu(), target_names=[\"Class 0\", \"Class 1\"], digits=4)\n",
    "    test_precision = precision_score(true_labels.cpu(), preds.cpu(), average=\"macro\")\n",
    "    test_recall = recall_score(true_labels.cpu(), preds.cpu(), average=\"macro\")\n",
    "    test_f1 = f1_score(true_labels.cpu(), preds.cpu(), average=\"macro\")\n",
    "    test_acc = accuracy_score(true_labels.cpu(), preds.cpu())\n",
    "    \n",
    "    print(\"\\nBest Model Classification Report on Test Set:\")\n",
    "    print(report)\n",
    "    print(\"Best Model Test Set Metrics:\")\n",
    "    print(f\"Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}, Accuracy: {test_acc:.4f}\")\n"
   ],
   "id": "55af7549f45aa83a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start random search with 100 combinations...\n",
      "\n",
      "Testing combination 1: threshold=0.1000, random_state=20, layers=3, hidden_channels=80, finetune_lr=0.001, pretrain_lr=0.0001, gamma=1.1000, alpha=0.7800, aug_method=edge_perturb, aug_ratio=0.1400, pretrain_epochs=5, temperature=0.0600, model_type=GAT, dropout_rate=0.2000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 2058380])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 6.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 6.6198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 6.4599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 6.4087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 6.3472\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 9147.8156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 423.2650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 70.6387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 41.9573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 28.3392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 16.7692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 12.8383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 21.6686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 7.2764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 5.8641\n",
      "Test Accuracy for current combination: 0.7788\n",
      "\n",
      "Testing combination 2: threshold=0.1100, random_state=10, layers=2, hidden_channels=100, finetune_lr=0.001, pretrain_lr=0.0001, gamma=2.6000, alpha=0.7800, aug_method=feature, aug_ratio=0.2300, pretrain_epochs=5, temperature=0.0800, model_type=GAT, dropout_rate=0.3000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 2058380])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 6.2369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 5.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 5.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 5.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 5.8625\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 10897.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 465.8899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 126.8829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 37.8223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 12.3148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 7.3389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 9.7308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 5.8217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 5.1809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 5.8941\n",
      "Test Accuracy for current combination: 0.7788\n",
      "\n",
      "Testing combination 3: threshold=0.1000, random_state=10, layers=2, hidden_channels=100, finetune_lr=0.001, pretrain_lr=0.0001, gamma=3.9000, alpha=0.2200, aug_method=edge_perturb, aug_ratio=0.2200, pretrain_epochs=5, temperature=0.0600, model_type=GAT, dropout_rate=0.1000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 2058380])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 6.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 5.8863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 5.8088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 5.7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 5.7195\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 5203.6895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 326.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 71.5722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 33.1535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 21.9605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 11.4665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 8.7263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 5.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 3.1762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 3.0478\n",
      "Test Accuracy for current combination: 0.7740\n",
      "\n",
      "Testing combination 4: threshold=0.1200, random_state=30, layers=4, hidden_channels=20, finetune_lr=0.001, pretrain_lr=1e-06, gamma=1.5000, alpha=0.7800, aug_method=node_drop, aug_ratio=0.2200, pretrain_epochs=5, temperature=0.0500, model_type=GraphSAGE, dropout_rate=0.1000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 1443080])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 12.2419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 12.2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 12.2382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 12.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 12.1408\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 98.2310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 3.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 1.5998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 1.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 0.7375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 0.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 0.6201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 0.6122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 0.5648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 0.5655\n",
      "Test Accuracy for current combination: 0.7788\n",
      "\n",
      "Testing combination 5: threshold=0.1500, random_state=0, layers=3, hidden_channels=160, finetune_lr=0.001, pretrain_lr=0.0001, gamma=1.3000, alpha=0.2200, aug_method=edge_perturb, aug_ratio=0.2500, pretrain_epochs=5, temperature=0.0900, model_type=GAT, dropout_rate=0.3000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 1035550])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 6.1257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 5.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 5.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 5.8977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 5.8683\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 6197.7545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 689.2573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 430.2231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 143.6143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 69.5102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 74.2927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 50.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 31.6264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 23.1925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 19.9747\n",
      "Test Accuracy for current combination: 0.7788\n",
      "\n",
      "Testing combination 6: threshold=0.1000, random_state=30, layers=3, hidden_channels=140, finetune_lr=0.001, pretrain_lr=1e-06, gamma=3.7000, alpha=0.2200, aug_method=edge_perturb, aug_ratio=0.0800, pretrain_epochs=5, temperature=0.0700, model_type=GraphSAGE, dropout_rate=0.2000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 2058380])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 5.7186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 5.6795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 5.6427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 5.5986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 5.5606\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 558.3074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 2.0765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 1.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 1.1749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 0.7645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 0.7407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 0.7293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 0.7354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 0.6518\n",
      "Test Accuracy for current combination: 0.7788\n",
      "\n",
      "Testing combination 7: threshold=0.0800, random_state=20, layers=3, hidden_channels=20, finetune_lr=0.001, pretrain_lr=1e-06, gamma=1.7000, alpha=0.2200, aug_method=edge_perturb, aug_ratio=0.0600, pretrain_epochs=5, temperature=0.0600, model_type=GraphSAGE, dropout_rate=0.1000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 3039048])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 6.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 6.8926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 6.8486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 6.8770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 6.8757\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 761.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 43.1914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 9.7437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 3.8971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 2.1322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 1.6995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 1.4181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 0.9430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 0.9363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 0.8958\n",
      "Test Accuracy for current combination: 0.7788\n",
      "\n",
      "Testing combination 8: threshold=0.1200, random_state=20, layers=2, hidden_channels=100, finetune_lr=0.001, pretrain_lr=1e-06, gamma=2.0000, alpha=0.2200, aug_method=node_drop, aug_ratio=0.1800, pretrain_epochs=5, temperature=0.0800, model_type=GAT, dropout_rate=0.3000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 1443080])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 6.8197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 6.7991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 6.7631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 6.7675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 6.7511\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 2161.8331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 87.8280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 28.5475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 19.0512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 10.5288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 9.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 6.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 4.7831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 4.8253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 84.2413\n",
      "Test Accuracy for current combination: 0.6547\n",
      "\n",
      "Testing combination 9: threshold=0.0600, random_state=10, layers=2, hidden_channels=60, finetune_lr=0.001, pretrain_lr=1e-05, gamma=3.8000, alpha=0.2200, aug_method=feature, aug_ratio=0.1800, pretrain_epochs=5, temperature=0.0600, model_type=GAT, dropout_rate=0.1000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 4710448])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 6.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 6.2983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 6.2200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 6.1539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 6.1062\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 883.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 141.8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 20.9115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 14.2879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 10.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 4.5137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 1.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 1.4219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 1.2616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 1.4925\n",
      "Test Accuracy for current combination: 0.7612\n",
      "\n",
      "Testing combination 10: threshold=0.1200, random_state=0, layers=2, hidden_channels=200, finetune_lr=0.001, pretrain_lr=0.0001, gamma=3.0000, alpha=0.7800, aug_method=node_drop, aug_ratio=0.1700, pretrain_epochs=5, temperature=0.0500, model_type=GraphSAGE, dropout_rate=0.3000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 1443080])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 5.2666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 4.8424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 4.6115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 4.4097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 4.2560\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 607.2387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 8.8253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 3.7357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 2.3117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 1.2533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 0.9812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 0.9150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 1.0619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 0.6612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 0.8500\n",
      "Test Accuracy for current combination: 0.7787\n",
      "\n",
      "Testing combination 11: threshold=0.1700, random_state=10, layers=2, hidden_channels=120, finetune_lr=0.001, pretrain_lr=0.0001, gamma=1.8000, alpha=0.2200, aug_method=feature, aug_ratio=0.2500, pretrain_epochs=5, temperature=0.0700, model_type=GraphSAGE, dropout_rate=0.2000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 754990])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 1/5, Contrast Loss: 3.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 2/5, Contrast Loss: 3.0467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 3/5, Contrast Loss: 2.5093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 4/5, Contrast Loss: 2.1459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Epoch 5/5, Contrast Loss: 1.8950\n",
      "========== 开始微调阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 1/10, CE Loss: 293.7344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 2/10, CE Loss: 7.1679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 3/10, CE Loss: 1.6463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 4/10, CE Loss: 1.2586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 5/10, CE Loss: 0.8114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 6/10, CE Loss: 0.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 7/10, CE Loss: 0.7534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 8/10, CE Loss: 0.6226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 9/10, CE Loss: 0.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tune Epoch 10/10, CE Loss: 0.5844\n",
      "Test Accuracy for current combination: 0.7788\n",
      "\n",
      "Testing combination 12: threshold=0.0700, random_state=30, layers=3, hidden_channels=240, finetune_lr=0.001, pretrain_lr=1e-06, gamma=2.4000, alpha=0.7800, aug_method=node_drop, aug_ratio=0.0500, pretrain_epochs=5, temperature=0.1000, model_type=GAT, dropout_rate=0.3000\n",
      "邻接矩阵转换完成！\n",
      "Edge index 维度: torch.Size([2, 4710448])\n",
      "========== 开始预训练阶段 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.87 GiB (GPU 0; 23.70 GiB total capacity; 16.92 GiB already allocated; 2.55 GiB free; 19.45 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 571\u001B[0m\n\u001B[1;32m    563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m best_overall_params, best_overall_model_state\n\u001B[1;32m    565\u001B[0m \u001B[38;5;66;03m#########################################\u001B[39;00m\n\u001B[1;32m    566\u001B[0m \u001B[38;5;66;03m# 7. 主程序：加载数据、随机搜索超参数、加载最佳模型并评估\u001B[39;00m\n\u001B[1;32m    567\u001B[0m \u001B[38;5;66;03m#########################################\u001B[39;00m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;66;03m# 注意：此处假定 X, y, adjacency_matrix, train_mask, valid_mask, test_mask 已经提前加载好，\u001B[39;00m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;66;03m# 且 edge_index 为形状 [2, num_edges] 的 torch.tensor 对象。\u001B[39;00m\n\u001B[0;32m--> 571\u001B[0m best_params, best_model_state \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalid_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mBest Hyperparameters:\u001B[39m\u001B[38;5;124m\"\u001B[39m, best_params)\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# 解包最佳超参数\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[2], line 546\u001B[0m, in \u001B[0;36mgrid_search\u001B[0;34m(X, y, train_mask, valid_mask, test_mask, n_iter)\u001B[0m\n\u001B[1;32m    543\u001B[0m criterion_ce \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m    544\u001B[0m criterion_contrast \u001B[38;5;241m=\u001B[39m SupConLoss(temperature\u001B[38;5;241m=\u001B[39mtemperature)\n\u001B[0;32m--> 546\u001B[0m best_model_epoch \u001B[38;5;241m=\u001B[39m \u001B[43mtwo_stage_train_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer_ft\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_ce\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    547\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mcriterion_contrast\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrain_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrain_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinetune_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    548\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43maug_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maug_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maug_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maug_ratio\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    549\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(best_model_epoch)\n\u001B[1;32m    550\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "Cell \u001B[0;32mIn[2], line 410\u001B[0m, in \u001B[0;36mtwo_stage_train_model\u001B[0;34m(data, model, optimizer, optimizer_ft, criterion_ce, criterion_contrast, pretrain_epochs, finetune_epochs, aug_method, aug_ratio, batch_size)\u001B[0m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;124;03m两阶段训练：\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;124;03m  第一阶段：预训练（仅用对比损失，mini-batch 方式）；\u001B[39;00m\n\u001B[1;32m    407\u001B[0m \u001B[38;5;124;03m  第二阶段：微调（仅用交叉熵损失，mini-batch 方式）。\u001B[39;00m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    409\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m========== 开始预训练阶段 ==========\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 410\u001B[0m best_pretrain_state \u001B[38;5;241m=\u001B[39m \u001B[43mpretrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion_contrast\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpretrain_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43maug_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maug_method\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maug_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maug_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    414\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(best_pretrain_state)\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m========== 开始微调阶段 ==========\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[2], line 328\u001B[0m, in \u001B[0;36mpretrain_model\u001B[0;34m(data, model, optimizer, criterion_contrast, num_epochs, aug_method, aug_ratio, batch_size)\u001B[0m\n\u001B[1;32m    326\u001B[0m x_aug2, edge_index2 \u001B[38;5;241m=\u001B[39m augment_data(sub_data, aug_method, aug_ratio)\n\u001B[1;32m    327\u001B[0m embedding_aug1 \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mencode(x_aug1, edge_index1)\n\u001B[0;32m--> 328\u001B[0m embedding_aug2 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_aug2\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    329\u001B[0m target_emb1 \u001B[38;5;241m=\u001B[39m embedding_aug1[mapping]\n\u001B[1;32m    330\u001B[0m target_emb2 \u001B[38;5;241m=\u001B[39m embedding_aug2[mapping]\n",
      "Cell \u001B[0;32mIn[2], line 109\u001B[0m, in \u001B[0;36mGAT.encode\u001B[0;34m(self, x, edge_index)\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"提取节点表示：依次通过 GAT 层、残差连接、ReLU 和 dropout\"\"\"\u001B[39;00m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m conv, res \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresiduals):\n\u001B[0;32m--> 109\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m     res_x \u001B[38;5;241m=\u001B[39m res(x)\n\u001B[1;32m    111\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(torch\u001B[38;5;241m.\u001B[39mrelu(out \u001B[38;5;241m+\u001B[39m res_x))\n",
      "File \u001B[0;32m~/anaconda3/envs/TabGNN/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_slow_forward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    888\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 889\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m itertools\u001B[38;5;241m.\u001B[39mchain(\n\u001B[1;32m    891\u001B[0m         _global_forward_hooks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[1;32m    892\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[1;32m    893\u001B[0m     hook_result \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, result)\n",
      "File \u001B[0;32m~/anaconda3/envs/TabGNN/lib/python3.9/site-packages/torch_geometric/nn/conv/gat_conv.py:152\u001B[0m, in \u001B[0;36mGATConv.forward\u001B[0;34m(self, x, edge_index, size, return_attention_weights)\u001B[0m\n\u001B[1;32m    149\u001B[0m         edge_index \u001B[38;5;241m=\u001B[39m set_diag(edge_index)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: OptPairTensor, alpha: OptPairTensor)\u001B[39;00m\n\u001B[0;32m--> 152\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_l\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_r\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m                     \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43malpha_l\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha_r\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    155\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/TabGNN/lib/python3.9/site-packages/torch_geometric/nn/conv/message_passing.py:237\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[0;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[1;32m    233\u001B[0m coll_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__collect__(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__user_args__, edge_index, size,\n\u001B[1;32m    234\u001B[0m                              kwargs)\n\u001B[1;32m    236\u001B[0m msg_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minspector\u001B[38;5;241m.\u001B[39mdistribute(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m, coll_dict)\n\u001B[0;32m--> 237\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmsg_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;66;03m# For `GNNExplainer`, we require a separate message and aggregate\u001B[39;00m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;66;03m# procedure since this allows us to inject the `edge_mask` into the\u001B[39;00m\n\u001B[1;32m    241\u001B[0m \u001B[38;5;66;03m# message passing computation scheme.\u001B[39;00m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__explain__:\n",
      "File \u001B[0;32m~/anaconda3/envs/TabGNN/lib/python3.9/site-packages/torch_geometric/nn/conv/gat_conv.py:183\u001B[0m, in \u001B[0;36mGATConv.message\u001B[0;34m(self, x_j, alpha_j, alpha_i, index, ptr, size_i)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m alpha\n\u001B[1;32m    182\u001B[0m alpha \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(alpha, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[0;32m--> 183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mx_j\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 2.87 GiB (GPU 0; 23.70 GiB total capacity; 16.92 GiB already allocated; 2.55 GiB free; 19.45 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "576de34efa53f20d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
