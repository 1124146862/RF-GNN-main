{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T22:19:55.420222Z",
     "start_time": "2025-02-05T22:19:31.474693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Standardize the input data\n",
    "def standard_input(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    return X_scaled_df\n",
    "\n",
    "# Load SGER1000 data and prepare X and y\n",
    "def load_data_SGER1000():\n",
    "    path = '/home/gehongfei/project/TabGNN/dataset/SGER1000.csv'\n",
    "    df = pd.read_csv(path, sep='\\s+')\n",
    "    \n",
    "    if 'kredit' not in df.columns:\n",
    "        print(\"Error: 'kredit' column not found.\")\n",
    "        return None, None\n",
    "\n",
    "    y = df['kredit']\n",
    "    X = df.drop(columns=['kredit'])\n",
    "    X = standard_input(X)\n",
    "    return X, y\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_data_SGER1000()\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(max_iter=1000),  # Increase max_iter for convergence\n",
    "    \"LDA\": LinearDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "# Evaluate models using 5-fold cross-validation\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    # Using cross_validate to evaluate multiple metrics\n",
    "    scores = cross_validate(model, X, y, cv=5, scoring=scoring)\n",
    "    \n",
    "    print(f\"{model_name} - Accuracy: {scores['test_accuracy'].mean():.4f} ± {scores['test_accuracy'].std():.4f}\")\n",
    "    print(f\"{model_name} - Precision: {scores['test_precision'].mean():.4f} ± {scores['test_precision'].std():.4f}\")\n",
    "    print(f\"{model_name} - Recall: {scores['test_recall'].mean():.4f} ± {scores['test_recall'].std():.4f}\")\n",
    "    print(f\"{model_name} - F1-score: {scores['test_f1'].mean():.4f} ± {scores['test_f1'].std():.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ],
   "id": "f6d7c07aa1a35e67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree...\n",
      "Decision Tree - Accuracy: 0.6650 ± 0.0454\n",
      "Decision Tree - Precision: 0.4498 ± 0.0606\n",
      "Decision Tree - Recall: 0.4633 ± 0.0488\n",
      "Decision Tree - F1-score: 0.4548 ± 0.0489\n",
      "--------------------------------------------------\n",
      "Evaluating Logistic Regression...\n",
      "Logistic Regression - Accuracy: 0.7360 ± 0.0926\n",
      "Logistic Regression - Precision: 0.6088 ± 0.1658\n",
      "Logistic Regression - Recall: 0.4567 ± 0.1153\n",
      "Logistic Regression - F1-score: 0.5140 ± 0.1287\n",
      "--------------------------------------------------\n",
      "Evaluating SVM...\n",
      "SVM - Accuracy: 0.7410 ± 0.0560\n",
      "SVM - Precision: 0.6241 ± 0.1311\n",
      "SVM - Recall: 0.4067 ± 0.0672\n",
      "SVM - F1-score: 0.4872 ± 0.0824\n",
      "--------------------------------------------------\n",
      "Evaluating Random Forest...\n",
      "Random Forest - Accuracy: 0.7430 ± 0.0543\n",
      "Random Forest - Precision: 0.6443 ± 0.1358\n",
      "Random Forest - Recall: 0.3767 ± 0.0696\n",
      "Random Forest - F1-score: 0.4693 ± 0.0834\n",
      "--------------------------------------------------\n",
      "Evaluating Naive Bayes...\n",
      "Naive Bayes - Accuracy: 0.6840 ± 0.0890\n",
      "Naive Bayes - Precision: 0.5036 ± 0.1032\n",
      "Naive Bayes - Recall: 0.6300 ± 0.1067\n",
      "Naive Bayes - F1-score: 0.5492 ± 0.0746\n",
      "--------------------------------------------------\n",
      "Evaluating MLP...\n",
      "MLP - Accuracy: 0.6910 ± 0.0500\n",
      "MLP - Precision: 0.4964 ± 0.0783\n",
      "MLP - Recall: 0.4433 ± 0.0523\n",
      "MLP - F1-score: 0.4642 ± 0.0517\n",
      "--------------------------------------------------\n",
      "Evaluating LDA...\n",
      "LDA - Accuracy: 0.7370 ± 0.0851\n",
      "LDA - Precision: 0.6073 ± 0.1515\n",
      "LDA - Recall: 0.4633 ± 0.1067\n",
      "LDA - F1-score: 0.5177 ± 0.1163\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T12:40:54.885131Z",
     "start_time": "2025-02-06T12:40:50.476536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Standardize the input data\n",
    "def standard_input(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "    return X_scaled_df\n",
    "\n",
    "# Load SGER1000 data and prepare X and y\n",
    "def load_data_SGER1000():\n",
    "    path = '/home/gehongfei/project/TabGNN/dataset/SGER1000.csv'\n",
    "    df = pd.read_csv(path, sep='\\s+')\n",
    "    \n",
    "    if 'kredit' not in df.columns:\n",
    "        print(\"Error: 'kredit' column not found.\")\n",
    "        return None, None\n",
    "\n",
    "    y = df['kredit']\n",
    "    X = df.drop(columns=['kredit'])\n",
    "    X = standard_input(X)\n",
    "    return X, y\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_data_SGER1000()\n",
    "\n",
    "# Split data into train (70%), validation (10%), and test (20%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"MLP\": MLPClassifier(max_iter=1000),  # Increase max_iter for convergence\n",
    "    \"LDA\": LinearDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "# Evaluate models on test set\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_test_pred)\n",
    "    prec = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    rec = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-score': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Report summary for all models\n",
    "print(\"\\nTest Performance Summary:\")\n",
    "for model, metrics in results.items():\n",
    "    print(f\"{model}: {metrics}\")\n"
   ],
   "id": "d47e7ca4df16ddd0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "\n",
      "Decision Tree Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80       143\n",
      "           1       0.47      0.40      0.43        57\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.62      0.61      0.61       200\n",
      "weighted avg       0.69      0.70      0.69       200\n",
      "\n",
      "Training Logistic Regression...\n",
      "\n",
      "Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       143\n",
      "           1       0.53      0.42      0.47        57\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.66      0.64      0.64       200\n",
      "weighted avg       0.71      0.73      0.72       200\n",
      "\n",
      "Training SVM...\n",
      "\n",
      "SVM Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84       143\n",
      "           1       0.62      0.42      0.50        57\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.71      0.66      0.67       200\n",
      "weighted avg       0.74      0.76      0.74       200\n",
      "\n",
      "Training Random Forest...\n",
      "\n",
      "Random Forest Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       143\n",
      "           1       0.56      0.42      0.48        57\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.67      0.64      0.65       200\n",
      "weighted avg       0.72      0.74      0.73       200\n",
      "\n",
      "Training Naive Bayes...\n",
      "\n",
      "Naive Bayes Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79       143\n",
      "           1       0.49      0.60      0.54        57\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.66      0.68      0.66       200\n",
      "weighted avg       0.73      0.71      0.72       200\n",
      "\n",
      "Training MLP...\n",
      "\n",
      "MLP Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.84       143\n",
      "           1       0.61      0.58      0.59        57\n",
      "\n",
      "    accuracy                           0.78       200\n",
      "   macro avg       0.72      0.72      0.72       200\n",
      "weighted avg       0.77      0.78      0.77       200\n",
      "\n",
      "Training LDA...\n",
      "\n",
      "LDA Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       143\n",
      "           1       0.54      0.44      0.49        57\n",
      "\n",
      "    accuracy                           0.73       200\n",
      "   macro avg       0.67      0.65      0.65       200\n",
      "weighted avg       0.72      0.73      0.73       200\n",
      "\n",
      "\n",
      "Test Performance Summary:\n",
      "Decision Tree: {'Accuracy': 0.7, 'Precision': 0.6877821327206379, 'Recall': 0.7, 'F1-score': 0.6927608779360801}\n",
      "Logistic Regression: {'Accuracy': 0.73, 'Precision': 0.7147741935483871, 'Recall': 0.73, 'F1-score': 0.7195538886695618}\n",
      "SVM: {'Accuracy': 0.76, 'Precision': 0.7438318203535594, 'Recall': 0.76, 'F1-score': 0.7446052631578948}\n",
      "Random Forest: {'Accuracy': 0.74, 'Precision': 0.7237831432380389, 'Recall': 0.74, 'F1-score': 0.7278666666666668}\n",
      "Naive Bayes: {'Accuracy': 0.71, 'Precision': 0.7299004314636575, 'Recall': 0.71, 'F1-score': 0.7174591588460203}\n",
      "MLP: {'Accuracy': 0.775, 'Precision': 0.7716324200913242, 'Recall': 0.775, 'F1-score': 0.7731272795286637}\n",
      "LDA: {'Accuracy': 0.735, 'Precision': 0.7213198757763974, 'Recall': 0.735, 'F1-score': 0.7257569219705142}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T17:31:56.469720Z",
     "start_time": "2025-02-06T17:31:56.456712Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b8090393530e1a10",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-06T17:31:56.986743Z",
     "start_time": "2025-02-06T17:31:56.983726Z"
    }
   },
   "cell_type": "code",
   "source": "X.shape",
   "id": "f2d5e118988b322c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 20)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b8e86631f9324a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
